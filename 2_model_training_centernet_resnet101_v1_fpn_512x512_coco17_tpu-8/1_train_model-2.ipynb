{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:20:11] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:20:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=872726;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=908021;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:20:15] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:20:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=715883;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=948685;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::469883407402:role/service-role/AmazonSageMaker-ExecutionRole-20250323T132116\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "          'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://krushnabucket1010/logs/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad5ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# # clone the repo and get the scripts\n",
    "# git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# # get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "# cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "# cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dab3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build and push the docker image. This code can be commented out after being run once.\n",
    "# # This will take around 10 mins.\n",
    "# image_name = 'tf2-object-detection'\n",
    "# !sh ./docker/build_and_push.sh $image_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469883407402.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20250324001031\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be adjusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4b1d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘source_dir/checkpoint’: File exists\n",
      "--2025-03-24 09:20:16--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.179.207, 64.233.180.207, 172.253.115.207, ...\n",
      "d.tensorflow.org)|142.251.179.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      " [application/x-tar]M)\n",
      "Saving to: ‘/tmp/efficientdet.tar.gz’\n",
      "\n",
      "........ .......... .......... ..........  0% 11.8M 4s\n",
      "........ .......... .......... ..........  0% 22.9M 3s\n",
      "... .......... .......... ..........  0% 23.5M 3s\n",
      "....... .......... .......... ..........  0% 22.9M 3s\n",
      ". .......... .......... .......... ..........  0% 24.1M 3s\n",
      "... .......... .......... .......... ..........  0% 23.3M 2s\n",
      "....... .......... .......... .......... ..........  0% 24.0M 2s\n",
      "........ .......... .......... .......... ..........  0% 21.3M 2s\n",
      ".... .......... .......... .......... ..........  0% 22.3M 2s\n",
      "........ .......... .......... ..........  0% 23.2M 2s\n",
      "........ .......... .......... ..........  1% 21.9M 2s\n",
      "... .......... .......... ..........  1% 22.8M 2s\n",
      "... .......... .......... ..........  1% 24.1M 2s\n",
      "......... .......... ..........  1% 23.3M 2s\n",
      "......... .......... ..........  1% 26.9M 2s\n",
      "..... .......... .......... .......... ..........  1% 30.0M 2s\n",
      "....... .......... ..........  1% 35.9M 2s\n",
      "....... .......... .......... .......... ..........  1% 25.0M 2s\n",
      "6.6M 2s .......... .......... .......... .......... ..........  1% 4\n",
      ".... .......... .......... .......... ..........  1% 22.0M 2s\n",
      ".. ..........  2% 40.6M 2s... .......... ........\n",
      "..... .......... .......... .......... ..........  2% 39.0M 2s\n",
      " .......... .......... ..........  2% 39.7M 2s\n",
      "......... .......... .......... ..........  2% 42.2M 2s\n",
      "........ .......... .......... .......... ..........  2% 22.5M 2s\n",
      "...... ..........  2% 39.5M 2s.......... ....\n",
      "..... .......... ..........  2% 40.3M 2s\n",
      ".. .......... .......... .......... ..........  2% 39.8M 2s\n",
      "... .......... .......... .......... ..........  2% 22.7M 2s\n",
      ". ..........  2% 39.7M 2s.... .......... .........\n",
      ".... .......... .......... .......... ..........  3% 39.1M 2s\n",
      "......... .......... ..........  3% 41.6M 2s\n",
      "........ .......... .......... ..........  3% 40.9M 2s\n",
      "....... .......... .......... .......... ..........  3% 22.0M 2s\n",
      "........ .......... ..........  3% 40.9M 2s\n",
      ".... .......... ..........  3% 39.6M 2s\n",
      "... .......... .......... ..........  3% 40.3M 2s\n",
      ".. .......... .......... .......... ..........  3% 23.1M 2s\n",
      " ..........  3% 39.3M 2s..... .......... ..........\n",
      "......... ..........  3% 39.6M 2s....... .\n",
      "........ .......... ..........  4% 38.8M 2s\n",
      "....... .......... .......... ..........  4% 41.3M 2s\n",
      "...... .......... .......... .......... ..........  4% 22.6M 2s\n",
      ".... ..........  4% 39.9M 2s. .......... ......\n",
      "... .......... ..........  4% 39.3M 2s\n",
      ".. .......... .......... ..........  4% 40.6M 2s\n",
      ". .......... .......... .......... ..........  4% 42.2M 2s\n",
      ".........  4% 21.4M 2s....... .......... .......... .\n",
      "........ ..........  4% 42.5M 2s........ ..\n",
      "....... .......... ..........  4% 39.0M 2s\n",
      "..... .......... .......... .......... ..........  5% 40.9M 2s\n",
      "..... .......... .......... .......... ..........  5% 22.4M 2s\n",
      ".... .......... .......... ..........  5% 40.9M 2s\n",
      ".. .......... ..........  5% 38.4M 2s.\n",
      "  5% 41.5M 2s..... .......... .......... .......... ..........\n",
      " .......... .......... .......... ..........  5% 40.7M 2s\n",
      "......... .......... .......... .......... ..........  5% 22.5M 2s\n",
      ".......... .......... .......... ..........  5% 39.5M 2s\n",
      "..... .......... ..........  5% 37.9M 2s\n",
      ".... .......... .......... ..........  5% 42.5M 2s\n",
      "... .......... .......... .......... ..........  6% 22.8M 2s\n",
      ". ..........  6% 37.3M 2s.... .......... .........\n",
      " .......... ..........  6% 42.0M 2s.....\n",
      "......... .......... ..........  6% 39.9M 2s\n",
      "........ .......... .......... ..........  6% 40.9M 2s\n",
      "....... .......... .......... .......... ..........  6% 21.2M 2s\n",
      "......... .......... .......... .......... ..........  6% 42.0M 2s\n",
      ".... .......... ..........  6% 40.8M 2s\n",
      "... .......... .......... ..........  6% 41.3M 2s\n",
      ".. .......... .......... .......... ..........  6% 22.5M 2s\n",
      "....... .......... .......... .......... ..........  7% 40.1M 2s\n",
      "......... ..........  7% 39.5M 2s....... .\n",
      "........ .......... ..........  7% 41.5M 2s\n",
      "....... .......... .......... ..........  7% 39.0M 1s\n",
      "...... .......... .......... .......... ..........  7% 22.8M 2s\n",
      "....... .......... .......... .......... ..........  7% 39.0M 1s\n",
      "... .......... ..........  7% 40.0M 1s\n",
      ".. .......... .......... ..........  7% 40.9M 1s\n",
      "..... .......... .......... .......... ..........  7% 40.6M 1s\n",
      ".........  7% 22.3M 1s....... .......... .......... .\n",
      "........ ..........  8% 39.4M 1s........ ..\n",
      "....... .......... ..........  8% 41.8M 1s\n",
      "...... .......... .......... ..........  8% 38.8M 1s\n",
      "..... .......... .......... .......... ..........  8% 22.4M 1s\n",
      "... ..........  8% 38.6M 1s.. .......... .......\n",
      ".. .......... ..........  8% 43.0M 1s.\n",
      "........ .......... .......... .......... ..........  8% 36.8M 1s\n",
      " .......... .......... .......... ..........  8% 44.0M 1s\n",
      "......... .......... .......... .......... ..........  8% 22.8M 1s\n",
      "....... .......... .......... .......... ..........  8% 37.6M 1s\n",
      ".. .......... .......... ..........  8% 40.0M 1s\n",
      "..... .......... .......... ..........  9% 40.9M 1s\n",
      ".... .......... .......... .......... ..........  9% 23.2M 1s\n",
      ".... .......... .......... ..........  9% 37.9M 1s\n",
      ". .......... ..........  9% 40.7M 1s...\n",
      " .......... .......... ..........  9% 37.6M 1s\n",
      "......... .......... .......... ..........  9% 43.0M 1s\n",
      "........ .......... .......... .......... ..........  9% 22.4M 1s\n",
      "...... ..........  9% 40.4M 1s.......... ....\n",
      "..... .......... ..........  9% 38.9M 1s\n",
      ".... .......... .......... ..........  9% 39.6M 1s\n",
      "... .......... .......... .......... .......... 10% 23.5M 1s\n",
      ". .......... 10% 39.3M 1s.... .......... .........\n",
      " .......... .......... 10% 38.0M 1s.....\n",
      ".. .......... .......... .......... .......... 10% 42.3M 1s\n",
      "........ .......... .......... .......... 10% 40.2M 1s\n",
      "....... .......... .......... .......... .......... 10% 21.9M 1s\n",
      "..... .......... 10% 40.2M 1s .......... .....\n",
      ".... .......... .......... 10% 41.5M 1s\n",
      "... .......... .......... .......... 10% 39.5M 1s\n",
      ". .......... .......... .......... .......... 10% 40.0M 1s\n",
      "......... 11% 22.9M 1s....... .......... .......... .\n",
      " .......... .......... .......... .......... .......... 11% 40.8M 1s\n",
      "... .......... .......... .......... 11% 35.4M 1s\n",
      "...... .......... .......... .......... 11% 45.3M 1s\n",
      "..... .......... .......... .......... .......... 11% 22.0M 1s\n",
      "... .......... .......... 11% 39.4M 1s\n",
      ".. .......... .......... 11% 39.7M 1s.\n",
      ". .......... .......... .......... 11% 39.9M 1s\n",
      " .......... .......... .......... .......... 11% 41.2M 1s\n",
      "......... .......... .......... .......... .......... 11% 23.1M 1s\n",
      "........ .......... 12% 37.2M 1s........ ..\n",
      "...... .......... .......... 12% 44.0M 1s\n",
      " .......... .......... .......... .......... .......... 12% 40.1M 1s\n",
      ".... .......... .......... .......... .......... 12% 22.4M 1s\n",
      "... .......... .......... .......... 12% 39.4M 1s\n",
      ". .......... .......... 12% 35.9M 1s...\n",
      " .......... .......... .......... 12% 45.6M 1s\n",
      "......... .......... .......... .......... 12% 40.5M 1s\n",
      "....... .......... 12% 22.6M 1s......... ...\n",
      "...... .......... 12% 39.8M 1s.......... ....\n",
      "..... .......... .......... 13% 39.0M 1s\n",
      "...... .......... .......... .......... .......... 13% 40.6M 1s\n",
      "... .......... .......... .......... .......... 13% 22.6M 1s\n",
      "......... .......... .......... .......... 13% 39.6M 1s\n",
      "...... .......... .......... .......... 13% 36.7M 1s\n",
      "......... .......... .......... 13% 44.6M 1s\n",
      "....... 13% 41.5M 1s......... .......... .......... ...\n",
      "... .......... .......... .......... 13% 22.0M 1s\n",
      "..... .......... 13% 37.3M 1s .......... .....\n",
      ".... .......... .......... 13% 42.5M 1s\n",
      "... .......... .......... .......... 14% 41.5M 1s\n",
      ".. .......... .......... .......... .......... 14% 22.9M 1s\n",
      "......... .......... .......... .......... .......... 14% 39.0M 1s\n",
      "  7200K .......... .......... .......... .......... .......... 14% 39.7M 1s\n",
      "........ .......... .......... 14% 38.7M 1s\n",
      "....... .......... .......... .......... 14% 42.4M 1s\n",
      ".... .......... .......... .......... .......... 14% 21.3M 1s\n",
      "  7400K .......... .......... .......... .......... .......... 14% 41.6M 1s\n",
      " .......... .......... .......... .......... .......... 14% 38.9M 1s\n",
      ".. .......... .......... .......... 14% 43.7M 1s\n",
      ".. .......... .......... 15% 38.3M 1s.\n",
      "......... 15% 22.7M 1s....... .......... .......... .\n",
      ". .......... .......... .......... .......... 15% 39.7M 1s\n",
      "....... .......... .......... 15% 39.1M 1s\n",
      "...... .......... .......... .......... 15% 41.6M 1s\n",
      "..... .......... .......... .......... .......... 15% 22.0M 1s\n",
      "... .......... 15% 41.8M 1s.. .......... .......\n",
      " 1s900K .......... .......... .......... .......... .......... 15% 40.7M\n",
      ". .......... .......... .......... 15% 38.2M 1s\n",
      " .......... .......... .......... .......... 15% 41.8M 1s\n",
      "......... .......... .......... .......... .......... 16% 21.4M 1s\n",
      "...... .......... 16% 37.7M 1s.......... ....\n",
      "..... .......... .......... 16% 41.8M 1s\n",
      ".... .......... .......... .......... 16% 47.1M 1s\n",
      "... .......... .......... .......... .......... 16% 22.8M 1s\n",
      ". .......... 16% 38.3M 1s.... .......... .........\n",
      "......... .......... .......... .......... .......... 16% 40.6M 1s\n",
      "6% 36.3M 1s....... .......... .......... .......... .......... 1\n",
      "........ .......... .......... .......... 16% 38.5M 1s\n",
      "...... .......... .......... .......... .......... 16% 23.8M 1s\n",
      ".... .......... .......... 16% 42.0M 1s\n",
      ".... .......... .......... 17% 40.2M 1s\n",
      "... .......... .......... .......... 17% 38.5M 1s\n",
      ".. .......... .......... .......... .......... 17% 23.7M 1s\n",
      "...... .......... 17% 36.6M 1s.......... ....\n",
      "..... .......... .......... 17% 47.5M 1s\n",
      " .......... 17% 24.6M 1s..... .......... ..........\n",
      "... .......... .......... .......... .......... 17% 40.9M 1s\n",
      "41.0M 1s.......... .......... .......... .......... .......... 17% \n",
      "...... .......... .......... .......... 17% 43.4M 1s\n",
      "..... .......... .......... .......... .......... 17% 25.7M 1s\n",
      "........ 18% 38.6M 1s........ .......... .......... ..\n",
      ".... .......... 18% 37.8M 1s. .......... ......\n",
      " .......... .......... 18% 39.3M 1s.....\n",
      "...... .......... .......... 18% 39.7M 1s\n",
      "... .......... .......... .......... 18% 40.6M 1s\n",
      "......... .......... .......... .......... 18% 43.0M 1s\n",
      "..... .......... .......... .......... .......... 18% 22.9M 1s\n",
      "......... .......... .......... .......... .......... 18%  197M 1s\n",
      "......... .......... .......... .......... .......... 18% 41.5M 1s\n",
      "....... .......... .......... .......... .......... 18% 44.9M 1s\n",
      "...... .......... .......... .......... 19% 42.8M 1s\n",
      ".... .......... 19% 44.5M 1s. .......... ......\n",
      "......... .......... .......... .......... 19% 43.6M 1s\n",
      "9% 45.4M 1s....... .......... .......... .......... .......... 1\n",
      "... .......... .......... .......... .......... 19% 43.5M 1s\n",
      "6.9M 1s .......... .......... .......... .......... .......... 19% 4\n",
      "  9900K .......... .......... .......... .......... .......... 19%  325M 1s\n",
      "... .......... .......... .......... .......... 19% 45.8M 1s\n",
      " .......... .......... .......... 19% 49.5M 1s\n",
      "....... .......... 19% 48.3M 1s......... ...\n",
      ".... .......... .......... .......... 20% 52.7M 1s\n",
      " 10150K .......... .......... .......... .......... .......... 20%  256M 1s\n",
      "K .......... .......... .......... .......... .......... 20% 54.8M 1s\n",
      ".... .......... .......... 20% 59.3M 1s\n",
      ". .......... 20% 60.2M 1s.... .......... .........\n",
      "..... 20% 61.0M 1s .......... .......... .......... .....\n",
      " 10400K .......... .......... .......... .......... .......... 20%  156M 1s\n",
      "0K .......... .......... .......... .......... .......... 20% 63.1M 1s\n",
      " .......... .......... 20% 61.9M 1s.....\n",
      "...... .......... 20% 76.4M 1s.......... ....\n",
      ".6M 1sK .......... .......... .......... .......... .......... 21% 77\n",
      "....... .......... .......... .......... 21%  220M 1s\n",
      "21% 75.8M 1s...... .......... .......... .......... .......... \n",
      "........ .......... .......... 21% 72.3M 1s\n",
      "...... 21% 91.6M 1s.......... .......... .......... ....\n",
      " 10850K .......... .......... .......... .......... .......... 21% 79.8M 1s\n",
      "00K .......... .......... .......... .......... .......... 21%  187M 1s\n",
      ".. 21% 73.8M 1s... .......... .......... .......... ........\n",
      "..... .......... 21% 71.2M 1s .......... .....\n",
      "8M 1s0K .......... .......... .......... .......... .......... 21% 99.\n",
      " 11100K .......... .......... .......... .......... .......... 22%  243M 1s\n",
      " .......... .......... .......... .......... 22% 84.0M 1s\n",
      "... .......... .......... .......... 22%  110M 1s\n",
      ". .......... 22% 98.3M 1s.... .......... .........\n",
      "s11300K .......... .......... .......... .......... .......... 22%  105M 1\n",
      "...... .......... .......... .......... .......... 22%  276M 1s\n",
      " 22%  108M 1s..... .......... .......... .......... ..........\n",
      " 11450K .......... .......... .......... .......... .......... 22%  102M 1s\n",
      "........ .......... .......... .......... .......... 22%  114M 1s\n",
      ". .......... .......... .......... .......... 22%  124M 1s\n",
      ".......... .......... 23%  236M 1s...... \n",
      "M 1s50K .......... .......... .......... .......... .......... 23%  109\n",
      " 11700K .......... .......... .......... .......... .......... 23%  127M 1s\n",
      ".......... .......... .......... .......... 23%  125M 1s\n",
      "........ .......... 23%  109M 1s........ ..\n",
      " 11850K .......... .......... .......... .......... .......... 23%  231M 1s\n",
      "11900K .......... .......... .......... .......... .......... 23%  133M 1s\n",
      ".... .......... .......... .......... 23%  121M 1s\n",
      ".. .......... 23%  179M 1s... .......... ........\n",
      "1s2050K .......... .......... .......... .......... .......... 23%  122M \n",
      " 12100K .......... .......... .......... .......... .......... 24%  130M 1s\n",
      "........ .......... .......... .......... 24%  134M 1s\n",
      "...... .......... 24%  157M 1s.......... ....\n",
      "79M 1sK .......... .......... .......... .......... .......... 24%  1\n",
      " 12300K .......... .......... .......... .......... .......... 24%  145M 1s\n",
      ". .......... .......... .......... .......... 24%  142M 1s\n",
      ".......... .......... 24%  127M 1s...... \n",
      "%  169M 1s........ .......... .......... .......... .......... 24\n",
      " 12500K .......... .......... .......... .......... .......... 24%  164M 1s\n",
      "..... .......... .......... .......... .......... 24%  124M 1s\n",
      "... .......... .......... 24%  218M 1s\n",
      ". 25%  173M 1s.... .......... .......... .......... .........\n",
      " 12700K .......... .......... .......... .......... .......... 25%  129M 1s\n",
      "......... .......... .......... .......... .......... 25%  168M 1s\n",
      "....... .......... .......... 25%  139M 1s\n",
      ".... .......... 25%  134M 1s. .......... ......\n",
      " 12900K .......... .......... .......... .......... .......... 25%  163M 1s\n",
      "50K .......... .......... .......... .......... .......... 25%  110M 1s\n",
      ". .......... .......... .......... 25%  146M 1s\n",
      ".......... 25%  127M 1s...... .......... .......... \n",
      " 13100K .......... .......... .......... .......... .......... 25%  117M 1s\n",
      " 13150K .......... .......... .......... .......... .......... 26%  145M 1s\n",
      "..... .......... .......... .......... 26%  119M 1s\n",
      "... .......... 26%  135M 1s.. .......... .......\n",
      " 1s300K .......... .......... .......... .......... .......... 26%  127M\n",
      " 13350K .......... .......... .......... .......... .......... 26%  120M 1s\n",
      "......... .......... .......... .......... 26%  131M 1s\n",
      "....... .......... 26%  136M 1s......... ...\n",
      "125M 1s .......... .......... .......... .......... .......... 26%  \n",
      " 13550K .......... .......... .......... .......... .......... 26%  113M 1s\n",
      ".. .......... .......... .......... .......... 26%  106M 1s\n",
      " .......... .......... 27%  118M 1s.....\n",
      "7%  156M 1s....... .......... .......... .......... .......... 2\n",
      " 13750K .......... .......... .......... .......... .......... 27%  107M 1s\n",
      "...... .......... .......... .......... .......... 27%  110M 1s\n",
      ".... .......... .......... 27%  159M 1s\n",
      ".. 27%  176M 1s... .......... .......... .......... ........\n",
      " 13950K .......... .......... .......... .......... .......... 27%  132M 1s\n",
      "...... .......... .......... .......... 27%  193M 1s\n",
      ".. .......... .......... .......... 27%  185M 1s\n",
      " .......... 27%  182M 1s..... .......... ..........\n",
      " 14150K .......... .......... .......... .......... .......... 28%  141M 1s\n",
      " 14200K .......... .......... .......... .......... .......... 28%  264M 1s\n",
      "...... .......... .......... .......... 28%  156M 1s\n",
      ".... .......... 28%  233M 1s. .......... ......\n",
      "M 1s50K .......... .......... .......... .......... .......... 28%  161\n",
      " 14400K .......... .......... .......... .......... .......... 28%  254M 1s\n",
      ".......... .......... .......... .......... 28%  201M 1s\n",
      "........ .......... 28%  183M 1s........ ..\n",
      " 172M 1s.......... .......... .......... .......... .......... 28% \n",
      " 14600K .......... .......... .......... .......... .......... 28%  227M 1s\n",
      "... .......... .......... .......... .......... 29%  173M 1s\n",
      ". .......... .......... 29%  139M 1s...\n",
      "29%  131M 1s...... .......... .......... .......... .......... \n",
      " 14800K .......... .......... .......... .......... .......... 29%  212M 1s\n",
      "....... .......... .......... .......... .......... 29%  117M 1s\n",
      "..... .......... .......... 29%  202M 1s\n",
      "... 29%  120M 1s.. .......... .......... .......... .......\n",
      " 15000K .......... .......... .......... .......... .......... 29%  145M 1s\n",
      " .......... .......... .......... .......... .......... 29%  243M 1s\n",
      "......... .......... .......... 29%  216M 1s\n",
      "....... 30%  207M 1s......... .......... .......... ...\n",
      " 15200K .......... .......... .......... .......... .......... 30%  246M 1s\n",
      "250K .......... .......... .......... .......... .......... 30%  236M 1s\n",
      ".. .......... .......... .......... 30%  180M 1s\n",
      " .......... 30%  186M 1s..... .......... ..........\n",
      " 15400K .......... .......... .......... .......... .......... 30%  283M 1s\n",
      " 15450K .......... .......... .......... .......... .......... 30%  204M 1s\n",
      "...... .......... .......... .......... 30%  227M 1s\n",
      ".. .......... .......... .......... 30%  188M 1s\n",
      " .......... 30%  225M 1s..... .......... ..........\n",
      " 15650K .......... .......... .......... .......... .......... 31%  221M 1s\n",
      " 15700K .......... .......... .......... .......... .......... 31%  191M 1s\n",
      "...... .......... .......... .......... 31%  131M 1s\n",
      "......... 31%  301M 1s....... .......... .......... .\n",
      " 15850K .......... .......... .......... .......... .......... 31%  205M 1s\n",
      "15900K .......... .......... .......... .......... .......... 31%  167M 1s\n",
      ".... .......... .......... .......... 31%  184M 1s\n",
      ".. .......... 31%  236M 1s... .......... ........\n",
      "1s6050K .......... .......... .......... .......... .......... 31%  191M \n",
      " 16100K .......... .......... .......... .......... .......... 31%  190M 1s\n",
      "........ .......... .......... .......... 32%  205M 1s\n",
      "...... .......... 32%  215M 1s.......... ....\n",
      "91M 1sK .......... .......... .......... .......... .......... 32%  2\n",
      " 16300K .......... .......... .......... .......... .......... 32%  173M 1s\n",
      ". .......... .......... .......... .......... 32%  191M 1s\n",
      ".......... .......... 32%  209M 1s...... \n",
      "%  289M 1s........ .......... .......... .......... .......... 32\n",
      " 16500K .......... .......... .......... .......... .......... 32%  164M 1s\n",
      "..... .......... .......... .......... .......... 32%  193M 1s\n",
      "... .......... .......... 32%  164M 1s\n",
      ". 32%  175M 1s.... .......... .......... .......... .........\n",
      " 16700K .......... .......... .......... .......... .......... 33%  173M 1s\n",
      "......... .......... .......... .......... .......... 33%  173M 1s\n",
      "....... .......... .......... 33%  171M 1s\n",
      "..... 33%  247M 1s .......... .......... .......... .....\n",
      " 16900K .......... .......... .......... .......... .......... 33%  154M 1s\n",
      "0K .......... .......... .......... .......... .......... 33%  179M 1s\n",
      " .......... .......... .......... 33%  245M 1s\n",
      "......... 33%  299M 1s....... .......... .......... .\n",
      " 17100K .......... .......... .......... .......... .......... 33%  167M 1s\n",
      "17150K .......... .......... .......... .......... .......... 33%  217M 1s\n",
      ".... .......... .......... .......... 34%  197M 1s\n",
      ".. .......... 34%  280M 1s... .......... ........\n",
      "1s7300K .......... .......... .......... .......... .......... 34%  196M \n",
      " 17350K .......... .......... .......... .......... .......... 34%  182M 1s\n",
      "........ .......... .......... .......... 34%  282M 1s\n",
      "...... .......... 34%  191M 1s.......... ....\n",
      "71M 1sK .......... .......... .......... .......... .......... 34%  2\n",
      " 17550K .......... .......... .......... .......... .......... 34%  153M 1s\n",
      ". .......... .......... .......... .......... 34%  167M 1s\n",
      ".......... .......... 34%  318M 1s...... \n",
      "%  232M 1s........ .......... .......... .......... .......... 35\n",
      " 17750K .......... .......... .......... .......... .......... 35%  274M 1s\n",
      "..... .......... .......... .......... .......... 35%  138M 1s\n",
      "... .......... .......... 35%  314M 1s\n",
      ". 35%  191M 1s.... .......... .......... .......... .........\n",
      " 17950K .......... .......... .......... .......... .......... 35%  282M 1s\n",
      "......... .......... .......... .......... .......... 35%  153M 1s\n",
      "....... .......... .......... 35%  357M 1s\n",
      "..... 35%  235M 1s .......... .......... .......... .....\n",
      " 18150K .......... .......... .......... .......... .......... 35%  289M 1s\n",
      "0K .......... .......... .......... .......... .......... 36%  214M 1s\n",
      " .......... .......... .......... 36%  312M 1s\n",
      "......... 36%  154M 1s....... .......... .......... .\n",
      " 18350K .......... .......... .......... .......... .......... 36%  274M 1s\n",
      "18400K .......... .......... .......... .......... .......... 36%  242M 1s\n",
      ".... .......... .......... .......... 36%  314M 1s\n",
      ".. .......... 36%  169M 1s... .......... ........\n",
      "1s8550K .......... .......... .......... .......... .......... 36%  211M \n",
      " 18600K .......... .......... .......... .......... .......... 36%  325M 1s\n",
      "........ .......... .......... .......... 36%  130M 1s\n",
      "...... .......... 37%  299M 1s.......... ....\n",
      "81M 1sK .......... .......... .......... .......... .......... 37%  1\n",
      " 18800K .......... .......... .......... .......... .......... 37%  213M 1s\n",
      ". .......... .......... .......... .......... 37%  336M 1s\n",
      ".......... .......... 37%  200M 1s...... \n",
      "%  147M 1s........ .......... .......... .......... .......... 37\n",
      " 19000K .......... .......... .......... .......... .......... 37%  316M 1s\n",
      "..... .......... .......... .......... .......... 37%  274M 1s\n",
      "... .......... .......... 37%  156M 1s\n",
      ". 37%  174M 1s.... .......... .......... .......... .........\n",
      " 19200K .......... .......... .......... .......... .......... 38%  321M 1s\n",
      "......... .......... .......... .......... .......... 38%  166M 1s\n",
      "....... .......... .......... 38%  259M 1s\n",
      "..... 38%  214M 1s .......... .......... .......... .....\n",
      " 19400K .......... .......... .......... .......... .......... 38%  354M 1s\n",
      "0K .......... .......... .......... .......... .......... 38%  216M 1s\n",
      " .......... .......... .......... 38%  339M 1s\n",
      "......... 38%  139M 1s....... .......... .......... .\n",
      " 19600K .......... .......... .......... .......... .......... 38%  163M 1s\n",
      "19650K .......... .......... .......... .......... .......... 38%  220M 1s\n",
      ".... .......... .......... .......... 39%  345M 1s\n",
      ".. .......... 39%  200M 1s... .......... ........\n",
      "1s9800K .......... .......... .......... .......... .......... 39%  338M \n",
      "..... .......... .......... 39%  304M 1s\n",
      "... 39%  320M 1s.. .......... .......... .......... .......\n",
      " 19950K .......... .......... .......... .......... .......... 39%  123M 1s\n",
      " .......... .......... .......... .......... .......... 39%  161M 1s\n",
      "......... .......... .......... 39%  153M 1s\n",
      "....... 39%  318M 1s......... .......... .......... ...\n",
      " 20150K .......... .......... .......... .......... .......... 39%  273M 1s\n",
      "200K .......... .......... .......... .......... .......... 40%  237M 1s\n",
      ".. .......... .......... .......... 40%  151M 1s\n",
      " .......... 40%  307M 1s..... .......... ..........\n",
      " 20350K .......... .......... .......... .......... .......... 40%  155M 1s\n",
      " 20400K .......... .......... .......... .......... .......... 40%  147M 1s\n",
      "...... .......... .......... .......... 40%  221M 1s\n",
      ".... .......... 40%  222M 1s. .......... ......\n",
      "M 1s50K .......... .......... .......... .......... .......... 40%  275\n",
      " 20600K .......... .......... .......... .......... .......... 40%  357M 1s\n",
      ".......... .......... .......... .......... 40%  259M 1s\n",
      "........ .......... 40%  324M 1s........ ..\n",
      " 133M 1s.......... .......... .......... .......... .......... 41% \n",
      " 20800K .......... .......... .......... .......... .......... 41%  339M 1s\n",
      "... .......... .......... .......... .......... 41%  178M 1s\n",
      ".. .......... .......... .......... 41%  303M 1s\n",
      " .......... 41%  212M 1s..... .......... ..........\n",
      " 21000K .......... .......... .......... .......... .......... 41%  294M 1s\n",
      " 21050K .......... .......... .......... .......... .......... 41%  239M 1s\n",
      "...... .......... .......... .......... 41%  314M 1s\n",
      ".... .......... 41%  164M 1s. .......... ......\n",
      "M 1s00K .......... .......... .......... .......... .......... 41%  323\n",
      " 21250K .......... .......... .......... .......... .......... 42%  246M 0s\n",
      ".......... .......... .......... .......... 42%  148M 0s\n",
      "........ .......... 42%  272M 0s........ ..\n",
      " 167M 0s.......... .......... .......... .......... .......... 42% \n",
      " 21450K .......... .......... .......... .......... .......... 42%  355M 0s\n",
      "... .......... .......... .......... .......... 42%  222M 0s\n",
      ". .......... .......... 42%  275M 0s...\n",
      "42%  180M 0s...... .......... .......... .......... .......... \n",
      " 21650K .......... .......... .......... .......... .......... 42%  176M 0s\n",
      "....... .......... .......... .......... .......... 42%  359M 0s\n",
      "..... .......... .......... 43%  144M 0s\n",
      "... 43%  269M 0s.. .......... .......... .......... .......\n",
      " 21850K .......... .......... .......... .......... .......... 43%  191M 0s\n",
      " .......... .......... .......... .......... .......... 43%  190M 0s\n",
      "......... .......... .......... 43%  179M 0s\n",
      "....... 43%  357M 0s......... .......... .......... ...\n",
      " 22050K .......... .......... .......... .......... .......... 43%  153M 0s\n",
      "100K .......... .......... .......... .......... .......... 43%  217M 0s\n",
      ".. .......... .......... .......... 43%  268M 0s\n",
      " .......... 43%  189M 0s..... .......... ..........\n",
      " 22250K .......... .......... .......... .......... .......... 44%  248M 0s\n",
      " 22300K .......... .......... .......... .......... .......... 44%  345M 0s\n",
      "...... .......... .......... .......... 44%  155M 0s\n",
      ".... .......... 44%  241M 0s. .......... ......\n",
      "M 0s50K .......... .......... .......... .......... .......... 44%  361\n",
      " 22500K .......... .......... .......... .......... .......... 44%  316M 0s\n",
      ".......... .......... .......... .......... 44%  235M 0s\n",
      "........ .......... 44%  145M 0s........ ..\n",
      " 289M 0s.......... .......... .......... .......... .......... 44% \n",
      " 22700K .......... .......... .......... .......... .......... 44%  258M 0s\n",
      "... .......... .......... .......... .......... 45%  149M 0s\n",
      ". .......... .......... 45%  326M 0s...\n",
      "45%  145M 0s...... .......... .......... .......... .......... \n",
      " 22900K .......... .......... .......... .......... .......... 45%  198M 0s\n",
      "....... .......... .......... .......... .......... 45%  267M 0s\n",
      "..... .......... .......... 45%  213M 0s\n",
      "... 45%  152M 0s.. .......... .......... .......... .......\n",
      " 23100K .......... .......... .......... .......... .......... 45%  139M 0s\n",
      " .......... .......... .......... .......... .......... 45%  169M 0s\n",
      "......... .......... .......... 45%  248M 0s\n",
      "....... 46%  142M 0s......... .......... .......... ...\n",
      " 23300K .......... .......... .......... .......... .......... 46%  194M 0s\n",
      "350K .......... .......... .......... .......... .......... 46%  252M 0s\n",
      ".. .......... .......... .......... 46%  176M 0s\n",
      " .......... 46%  224M 0s..... .......... ..........\n",
      " 23500K .......... .......... .......... .......... .......... 46%  165M 0s\n",
      " 23550K .......... .......... .......... .......... .......... 46%  191M 0s\n",
      "...... .......... .......... .......... 46%  249M 0s\n",
      ".... .......... 46%  156M 0s. .......... ......\n",
      "M 0s00K .......... .......... .......... .......... .......... 46%  247\n",
      " 23750K .......... .......... .......... .......... .......... 47%  309M 0s\n",
      ".......... .......... .......... .......... 47%  312M 0s\n",
      "........ .......... 47%  215M 0s........ ..\n",
      " 143M 0s.......... .......... .......... .......... .......... 47% \n",
      " 23950K .......... .......... .......... .......... .......... 47%  213M 0s\n",
      "... .......... .......... .......... .......... 47%  233M 0s\n",
      ". .......... .......... 47%  194M 0s...\n",
      "47%  193M 0s...... .......... .......... .......... .......... \n",
      " 24150K .......... .......... .......... .......... .......... 47%  265M 0s\n",
      "....... .......... .......... .......... .......... 47%  338M 0s\n",
      "..... .......... .......... 48%  324M 0s\n",
      "... 48%  248M 0s.. .......... .......... .......... .......\n",
      " 24350K .......... .......... .......... .......... .......... 48%  151M 0s\n",
      " .......... .......... .......... .......... .......... 48%  162M 0s\n",
      "......... .......... .......... 48%  232M 0s\n",
      "....... 48%  180M 0s......... .......... .......... ...\n",
      " 24550K .......... .......... .......... .......... .......... 48%  174M 0s\n",
      "600K .......... .......... .......... .......... .......... 48%  300M 0s\n",
      ".. .......... .......... .......... 48%  364M 0s\n",
      " .......... 48%  314M 0s..... .......... ..........\n",
      " 24750K .......... .......... .......... .......... .......... 48%  242M 0s\n",
      " 24800K .......... .......... .......... .......... .......... 49%  361M 0s\n",
      "...... .......... .......... .......... 49%  136M 0s\n",
      ".... .......... 49%  186M 0s. .......... ......\n",
      "M 0s50K .......... .......... .......... .......... .......... 49%  156\n",
      " 25000K .......... .......... .......... .......... .......... 49%  158M 0s\n",
      ".......... .......... .......... .......... 49%  345M 0s\n",
      "........ .......... 49%  278M 0s........ ..\n",
      " 280M 0s.......... .......... .......... .......... .......... 49% \n",
      " 25200K .......... .......... .......... .......... .......... 49%  348M 0s\n",
      "... .......... .......... .......... .......... 49%  297M 0s\n",
      ". .......... .......... 50%  281M 0s...\n",
      "50%  137M 0s...... .......... .......... .......... .......... \n",
      " 25400K .......... .......... .......... .......... .......... 50%  182M 0s\n",
      "....... .......... .......... .......... .......... 50%  156M 0s\n",
      "..... .......... .......... 50%  196M 0s\n",
      "... 50%  205M 0s.. .......... .......... .......... .......\n",
      " 25600K .......... .......... .......... .......... .......... 50%  310M 0s\n",
      " .......... .......... .......... .......... .......... 50%  342M 0s\n",
      "......... .......... .......... 50%  364M 0s\n",
      "....... 50%  267M 0s......... .......... .......... ...\n",
      " 25800K .......... .......... .......... .......... .......... 51%  323M 0s\n",
      "850K .......... .......... .......... .......... .......... 51%  294M 0s\n",
      ".. .......... .......... .......... 51%  318M 0s\n",
      " .......... 51%  273M 0s..... .......... ..........\n",
      " 26000K .......... .......... .......... .......... .......... 51%  348M 0s\n",
      " 26050K .......... .......... .......... .......... .......... 51%  335M 0s\n",
      "...... .......... .......... .......... 51%  300M 0s\n",
      ".... .......... 51%  303M 0s. .......... ......\n",
      "M 0s00K .......... .......... .......... .......... .......... 51%  324\n",
      " 26250K .......... .......... .......... .......... .......... 51%  293M 0s\n",
      ".......... .......... .......... .......... 52%  355M 0s\n",
      "........ .......... 52%  256M 0s........ ..\n",
      " 292M 0s.......... .......... .......... .......... .......... 52% \n",
      " 26450K .......... .......... .......... .......... .......... 52%  334M 0s\n",
      "... .......... .......... .......... .......... 52%  305M 0s\n",
      ". .......... .......... 52%  281M 0s...\n",
      "52% 4.11M 0s...... .......... .......... .......... .......... \n",
      " 26650K .......... .......... .......... .......... .......... 52%  148M 0s\n",
      "....... .......... .......... .......... .......... 52% 89.8M 0s\n",
      "..... .......... .......... 52%  153M 0s\n",
      "... 53%  190M 0s.. .......... .......... .......... .......\n",
      " 26850K .......... .......... .......... .......... .......... 53%  150M 0s\n",
      " .......... .......... .......... .......... .......... 53%  189M 0s\n",
      "... 53%  167M 0s.. .......... .......... .......... .......\n",
      " 27000K .......... .......... .......... .......... .......... 53%  202M 0s\n",
      " .......... .......... .......... .......... .......... 53%  187M 0s\n",
      "......... .......... .......... 53%  135M 0s\n",
      "....... 53%  182M 0s......... .......... .......... ...\n",
      " 27200K .......... .......... .......... .......... .......... 53%  130M 0s\n",
      "250K .......... .......... .......... .......... .......... 53%  201M 0s\n",
      ".. .......... .......... .......... 54%  143M 0s\n",
      " .......... 54%  161M 0s..... .......... ..........\n",
      " 27400K .......... .......... .......... .......... .......... 54%  166M 0s\n",
      " 27450K .......... .......... .......... .......... .......... 54%  185M 0s\n",
      "...... .......... .......... .......... 54%  151M 0s\n",
      ".... .......... 54%  184M 0s. .......... ......\n",
      "M 0s00K .......... .......... .......... .......... .......... 54%  164\n",
      " 27650K .......... .......... .......... .......... .......... 54%  182M 0s\n",
      ".......... .......... .......... .......... 54%  144M 0s\n",
      "........ .......... 54%  205M 0s........ ..\n",
      " 149M 0s.......... .......... .......... .......... .......... 55% \n",
      " 27850K .......... .......... .......... .......... .......... 55%  196M 0s\n",
      "... .......... .......... .......... .......... 55%  117M 0s\n",
      ". .......... .......... 55%  197M 0s...\n",
      "55%  177M 0s...... .......... .......... .......... .......... \n",
      " 28050K .......... .......... .......... .......... .......... 55%  154M 0s\n",
      "....... .......... .......... .......... .......... 55%  163M 0s\n",
      "..... .......... .......... 55%  157M 0s\n",
      "... 55%  154M 0s.. .......... .......... .......... .......\n",
      "..... .......... 55%  171M 0s .......... .....\n",
      "7M 0s0K .......... .......... .......... .......... .......... 56%  17\n",
      " 28350K .......... .......... .......... .......... .......... 56%  239M 0s\n",
      " .......... .......... .......... .......... 56%  102M 0s\n",
      "......... .......... 56%  157M 0s....... .\n",
      "  143M 0s......... .......... .......... .......... .......... 56%\n",
      " 28550K .......... .......... .......... .......... .......... 56%  140M 0s\n",
      ".... .......... .......... .......... .......... 56%  185M 0s\n",
      ".. .......... .......... 56%  166M 0s.\n",
      " 56%  155M 0s..... .......... .......... .......... ..........\n",
      " 28750K .......... .......... .......... .......... .......... 56%  162M 0s\n",
      "........ .......... .......... .......... .......... 56%  180M 0s\n",
      "...... .......... .......... 57%  165M 0s\n",
      ".... 57%  158M 0s. .......... .......... .......... ......\n",
      " 28950K .......... .......... .......... .......... .......... 57%  177M 0s\n",
      "K .......... .......... .......... .......... .......... 57%  181M 0s\n",
      ".......... .......... .......... 57%  181M 0s\n",
      "........ 57%  150M 0s........ .......... .......... ..\n",
      " 29150K .......... .......... .......... .......... .......... 57%  196M 0s\n",
      "9200K .......... .......... .......... .......... .......... 57%  203M 0s\n",
      "... .......... .......... .......... 57%  221M 0s\n",
      ". .......... 57%  158M 0s.... .......... .........\n",
      "s29350K .......... .......... .......... .......... .......... 58%  300M 0\n",
      " 29400K .......... .......... .......... .......... .......... 58%  223M 0s\n",
      "....... .......... .......... .......... 58%  236M 0s\n",
      "..... .......... 58%  144M 0s .......... .....\n",
      "3M 0s0K .......... .......... .......... .......... .......... 58%  27\n",
      " 29600K .......... .......... .......... .......... .......... 58%  179M 0s\n",
      " .......... .......... .......... .......... 58%  200M 0s\n",
      "......... .......... 58%  193M 0s....... .\n",
      "  167M 0s......... .......... .......... .......... .......... 58%\n",
      " 29800K .......... .......... .......... .......... .......... 58%  246M 0s\n",
      ".... .......... .......... .......... .......... 59%  206M 0s\n",
      ".. .......... .......... 59%  273M 0s.\n",
      " 59%  181M 0s..... .......... .......... .......... ..........\n",
      " 30000K .......... .......... .......... .......... .......... 59%  279M 0s\n",
      "........ .......... .......... .......... .......... 59%  160M 0s\n",
      "...... .......... .......... 59%  139M 0s\n",
      ".... 59%  216M 0s. .......... .......... .......... ......\n",
      " 30200K .......... .......... .......... .......... .......... 59%  183M 0s\n",
      "K .......... .......... .......... .......... .......... 59%  190M 0s\n",
      ".......... .......... .......... 59%  122M 0s\n",
      "........ 60%  143M 0s........ .......... .......... ..\n",
      " 30400K .......... .......... .......... .......... .......... 60%  222M 0s\n",
      "0450K .......... .......... .......... .......... .......... 60%  176M 0s\n",
      "... .......... .......... .......... 60%  154M 0s\n",
      ". .......... 60%  219M 0s.... .......... .........\n",
      "s30600K .......... .......... .......... .......... .......... 60%  251M 0\n",
      " 30650K .......... .......... .......... .......... .......... 60%  199M 0s\n",
      "....... .......... .......... .......... 60%  154M 0s\n",
      "..... .......... 60%  145M 0s .......... .....\n",
      "4M 0s0K .......... .......... .......... .......... .......... 60%  20\n",
      " 30850K .......... .......... .......... .......... .......... 61%  213M 0s\n",
      " .......... .......... .......... .......... 61%  190M 0s\n",
      "......... .......... 61%  165M 0s....... .\n",
      "  226M 0s......... .......... .......... .......... .......... 61%\n",
      " 31050K .......... .......... .......... .......... .......... 61%  181M 0s\n",
      ".... .......... .......... .......... .......... 61%  156M 0s\n",
      ".. .......... .......... 61%  225M 0s.\n",
      " 61%  242M 0s..... .......... .......... .......... ..........\n",
      " 31250K .......... .......... .......... .......... .......... 61%  189M 0s\n",
      "........ .......... .......... .......... .......... 61%  244M 0s\n",
      "...... .......... .......... 62%  169M 0s\n",
      ".... 62%  166M 0s. .......... .......... .......... ......\n",
      " 31450K .......... .......... .......... .......... .......... 62%  200M 0s\n",
      "K .......... .......... .......... .......... .......... 62%  158M 0s\n",
      ".......... .......... .......... 62%  229M 0s\n",
      "........ 62%  229M 0s........ .......... .......... ..\n",
      " 31650K .......... .......... .......... .......... .......... 62%  202M 0s\n",
      "1700K .......... .......... .......... .......... .......... 62%  287M 0s\n",
      "... .......... .......... .......... 62%  286M 0s\n",
      ". .......... 62%  160M 0s.... .......... .........\n",
      "s31850K .......... .......... .......... .......... .......... 63%  222M 0\n",
      " 31900K .......... .......... .......... .......... .......... 63%  207M 0s\n",
      "....... .......... .......... .......... 63%  192M 0s\n",
      "..... .......... 63%  216M 0s .......... .....\n",
      "2M 0s0K .......... .......... .......... .......... .......... 63%  21\n",
      " 32100K .......... .......... .......... .......... .......... 63%  243M 0s\n",
      " .......... .......... .......... .......... 63%  167M 0s\n",
      "......... .......... 63%  306M 0s....... .\n",
      "  179M 0s......... .......... .......... .......... .......... 63%\n",
      " 32300K .......... .......... .......... .......... .......... 63%  144M 0s\n",
      ".... .......... .......... .......... .......... 64%  208M 0s\n",
      ".. .......... .......... 64%  155M 0s.\n",
      " 64%  246M 0s..... .......... .......... .......... ..........\n",
      " 32500K .......... .......... .......... .......... .......... 64%  151M 0s\n",
      "........ .......... .......... .......... .......... 64%  206M 0s\n",
      "...... .......... .......... 64%  351M 0s\n",
      ".... 64%  212M 0s. .......... .......... .......... ......\n",
      " 32700K .......... .......... .......... .......... .......... 64%  144M 0s\n",
      "K .......... .......... .......... .......... .......... 64%  180M 0s\n",
      ".......... .......... .......... 64%  232M 0s\n",
      "........ 64%  178M 0s........ .......... .......... ..\n",
      " 32900K .......... .......... .......... .......... .......... 65%  218M 0s\n",
      "2950K .......... .......... .......... .......... .......... 65%  182M 0s\n",
      "... .......... .......... .......... 65%  246M 0s\n",
      ". .......... 65%  179M 0s.... .......... .........\n",
      "s33100K .......... .......... .......... .......... .......... 65%  144M 0\n",
      " 33150K .......... .......... .......... .......... .......... 65%  218M 0s\n",
      "....... .......... .......... .......... 65%  173M 0s\n",
      "..... .......... 65%  212M 0s .......... .....\n",
      "7M 0s0K .......... .......... .......... .......... .......... 65%  18\n",
      " 33350K .......... .......... .......... .......... .......... 65%  199M 0s\n",
      " .......... .......... .......... .......... 66%  199M 0s\n",
      "......... .......... 66%  328M 0s....... .\n",
      "  166M 0s......... .......... .......... .......... .......... 66%\n",
      " 33550K .......... .......... .......... .......... .......... 66%  231M 0s\n",
      ".... .......... .......... .......... .......... 66%  294M 0s\n",
      ".. .......... .......... 66%  173M 0s.\n",
      " 66%  212M 0s..... .......... .......... .......... ..........\n",
      " 33750K .......... .......... .......... .......... .......... 66%  169M 0s\n",
      "........ .......... .......... .......... .......... 66%  201M 0s\n",
      "...... .......... .......... 66%  248M 0s\n",
      ".... 67%  175M 0s. .......... .......... .......... ......\n",
      " 33950K .......... .......... .......... .......... .......... 67%  156M 0s\n",
      "K .......... .......... .......... .......... .......... 67%  217M 0s\n",
      ".......... .......... .......... 67%  223M 0s\n",
      "........ 67%  158M 0s........ .......... .......... ..\n",
      " 34150K .......... .......... .......... .......... .......... 67%  193M 0s\n",
      "4200K .......... .......... .......... .......... .......... 67%  232M 0s\n",
      "... .......... .......... .......... 67%  173M 0s\n",
      ". .......... 67%  202M 0s.... .......... .........\n",
      "s34350K .......... .......... .......... .......... .......... 67%  180M 0\n",
      " 34400K .......... .......... .......... .......... .......... 68%  226M 0s\n",
      "....... .......... .......... .......... 68%  302M 0s\n",
      "..... .......... 68%  163M 0s .......... .....\n",
      "2M 0s0K .......... .......... .......... .......... .......... 68%  18\n",
      " 34600K .......... .......... .......... .......... .......... 68%  218M 0s\n",
      " .......... .......... .......... .......... 68%  179M 0s\n",
      "......... .......... 68%  175M 0s....... .\n",
      "  214M 0s......... .......... .......... .......... .......... 68%\n",
      " 34800K .......... .......... .......... .......... .......... 68%  174M 0s\n",
      ".... .......... .......... .......... .......... 68%  179M 0s\n",
      ".. .......... .......... 69%  161M 0s.\n",
      " 69%  218M 0s..... .......... .......... .......... ..........\n",
      " 35000K .......... .......... .......... .......... .......... 69%  164M 0s\n",
      "........ .......... .......... .......... .......... 69%  245M 0s\n",
      "...... .......... .......... 69%  177M 0s\n",
      ".... 69%  196M 0s. .......... .......... .......... ......\n",
      " 35200K .......... .......... .......... .......... .......... 69%  194M 0s\n",
      "K .......... .......... .......... .......... .......... 69%  223M 0s\n",
      ".......... .......... .......... 69%  150M 0s\n",
      "........ 69%  237M 0s........ .......... .......... ..\n",
      " 35400K .......... .......... .......... .......... .......... 70%  187M 0s\n",
      "5450K .......... .......... .......... .......... .......... 70%  306M 0s\n",
      "... .......... .......... .......... 70%  133M 0s\n",
      ". .......... 70%  241M 0s.... .......... .........\n",
      "s35600K .......... .......... .......... .......... .......... 70%  163M 0\n",
      " 35650K .......... .......... .......... .......... .......... 70%  232M 0s\n",
      "....... .......... .......... .......... 70%  143M 0s\n",
      "..... .......... 70%  229M 0s .......... .....\n",
      "9M 0s0K .......... .......... .......... .......... .......... 70%  14\n",
      " 35850K .......... .......... .......... .......... .......... 70%  242M 0s\n",
      " .......... .......... .......... .......... 71%  150M 0s\n",
      "......... .......... 71%  193M 0s....... .\n",
      "  193M 0s......... .......... .......... .......... .......... 71%\n",
      " 36050K .......... .......... .......... .......... .......... 71%  206M 0s\n",
      ".... .......... .......... .......... .......... 71%  240M 0s\n",
      ".. .......... .......... 71%  175M 0s.\n",
      " 71%  224M 0s..... .......... .......... .......... ..........\n",
      " 36250K .......... .......... .......... .......... .......... 71%  248M 0s\n",
      "........ .......... .......... .......... .......... 71%  197M 0s\n",
      "...... .......... .......... 71%  158M 0s\n",
      ".... 72%  262M 0s. .......... .......... .......... ......\n",
      " 36450K .......... .......... .......... .......... .......... 72%  225M 0s\n",
      "K .......... .......... .......... .......... .......... 72%  180M 0s\n",
      ".......... .......... .......... 72%  316M 0s\n",
      "........ 72%  193M 0s........ .......... .......... ..\n",
      " 36650K .......... .......... .......... .......... .......... 72%  162M 0s\n",
      "6700K .......... .......... .......... .......... .......... 72%  202M 0s\n",
      "... .......... .......... .......... 72%  157M 0s\n",
      ". .......... 72%  204M 0s.... .......... .........\n",
      "s36850K .......... .......... .......... .......... .......... 72%  326M 0\n",
      " 36900K .......... .......... .......... .......... .......... 72%  203M 0s\n",
      "....... .......... .......... .......... 73%  191M 0s\n",
      "..... .......... 73%  301M 0s .......... .....\n",
      "8M 0s0K .......... .......... .......... .......... .......... 73%  17\n",
      " 37100K .......... .......... .......... .......... .......... 73%  239M 0s\n",
      " .......... .......... .......... .......... 73%  197M 0s\n",
      "......... .......... 73%  168M 0s....... .\n",
      "  168M 0s......... .......... .......... .......... .......... 73%\n",
      " 37300K .......... .......... .......... .......... .......... 73%  258M 0s\n",
      ".... .......... .......... .......... .......... 73%  187M 0s\n",
      ".. .......... .......... 73%  211M 0s.\n",
      " 74%  326M 0s..... .......... .......... .......... ..........\n",
      " 37500K .......... .......... .......... .......... .......... 74%  152M 0s\n",
      "........ .......... .......... .......... .......... 74%  231M 0s\n",
      "...... .......... .......... 74%  242M 0s\n",
      ".... 74%  188M 0s. .......... .......... .......... ......\n",
      " 37700K .......... .......... .......... .......... .......... 74%  282M 0s\n",
      "K .......... .......... .......... .......... .......... 74%  208M 0s\n",
      ".......... .......... .......... 74%  356M 0s\n",
      "........ 74%  197M 0s........ .......... .......... ..\n",
      " 37900K .......... .......... .......... .......... .......... 74%  283M 0s\n",
      "7950K .......... .......... .......... .......... .......... 75%  173M 0s\n",
      "... .......... .......... .......... 75%  177M 0s\n",
      ". .......... 75%  315M 0s.... .......... .........\n",
      "s38100K .......... .......... .......... .......... .......... 75%  217M 0\n",
      " 38150K .......... .......... .......... .......... .......... 75%  182M 0s\n",
      "....... .......... .......... .......... 75%  311M 0s\n",
      "..... .......... 75%  220M 0s .......... .....\n",
      "9M 0s0K .......... .......... .......... .......... .......... 75%  25\n",
      " 38350K .......... .......... .......... .......... .......... 75%  166M 0s\n",
      " .......... .......... .......... .......... 75%  163M 0s\n",
      "......... .......... 76%  247M 0s....... .\n",
      "  254M 0s......... .......... .......... .......... .......... 76%\n",
      " 38550K .......... .......... .......... .......... .......... 76%  328M 0s\n",
      ".... .......... .......... .......... .......... 76%  317M 0s\n",
      ".. .......... .......... 76%  346M 0s.\n",
      " 76%  131M 0s..... .......... .......... .......... ..........\n",
      " 38750K .......... .......... .......... .......... .......... 76%  179M 0s\n",
      "........ .......... .......... .......... .......... 76%  162M 0s\n",
      "...... .......... .......... 76%  160M 0s\n",
      ".... 76%  156M 0s. .......... .......... .......... ......\n",
      " 38950K .......... .......... .......... .......... .......... 77%  297M 0s\n",
      "K .......... .......... .......... .......... .......... 77%  328M 0s\n",
      ".......... .......... .......... 77%  305M 0s\n",
      "........ 77%  206M 0s........ .......... .......... ..\n",
      " 39150K .......... .......... .......... .......... .......... 77%  149M 0s\n",
      "9200K .......... .......... .......... .......... .......... 77%  191M 0s\n",
      "... .......... .......... .......... 77%  168M 0s\n",
      ". .......... 77%  191M 0s.... .......... .........\n",
      "s39350K .......... .......... .......... .......... .......... 77%  215M 0\n",
      " 39400K .......... .......... .......... .......... .......... 77%  340M 0s\n",
      "....... .......... .......... .......... 78%  325M 0s\n",
      "..... .......... 78%  238M 0s .......... .....\n",
      "3M 0s0K .......... .......... .......... .......... .......... 78%  16\n",
      " 39600K .......... .......... .......... .......... .......... 78%  181M 0s\n",
      " .......... .......... .......... .......... 78%  150M 0s\n",
      "......... .......... 78%  230M 0s....... .\n",
      " 39750K .......... .......... .......... .......... .......... 78%  230M 0s\n",
      "......... .......... .......... .......... .......... 78%  303M 0s\n",
      "....... .......... .......... 78%  181M 0s\n",
      "..... 78%  271M 0s .......... .......... .......... .....\n",
      " 39950K .......... .......... .......... .......... .......... 79%  169M 0s\n",
      "0K .......... .......... .......... .......... .......... 79%  173M 0s\n",
      " .......... .......... .......... 79%  154M 0s\n",
      "......... 79%  184M 0s....... .......... .......... .\n",
      " 40150K .......... .......... .......... .......... .......... 79%  272M 0s\n",
      "40200K .......... .......... .......... .......... .......... 79%  216M 0s\n",
      ".... .......... .......... .......... 79%  156M 0s\n",
      ".. .......... 79%  144M 0s... .......... ........\n",
      "0s0350K .......... .......... .......... .......... .......... 79%  160M \n",
      " 40400K .......... .......... .......... .......... .......... 79%  242M 0s\n",
      "........ .......... .......... .......... 80%  191M 0s\n",
      "...... .......... 80%  246M 0s.......... ....\n",
      "90M 0sK .......... .......... .......... .......... .......... 80%  1\n",
      " 40600K .......... .......... .......... .......... .......... 80%  181M 0s\n",
      ". .......... .......... .......... .......... 80%  196M 0s\n",
      ".......... .......... 80%  188M 0s...... \n",
      "%  167M 0s........ .......... .......... .......... .......... 80\n",
      " 40800K .......... .......... .......... .......... .......... 80%  181M 0s\n",
      "..... .......... .......... .......... .......... 80%  253M 0s\n",
      "... .......... .......... 80%  158M 0s\n",
      ". 80%  233M 0s.... .......... .......... .......... .........\n",
      " 41000K .......... .......... .......... .......... .......... 81%  174M 0s\n",
      "......... .......... .......... .......... .......... 81%  304M 0s\n",
      "....... .......... .......... 81%  177M 0s\n",
      "..... 81%  195M 0s .......... .......... .......... .....\n",
      " 41200K .......... .......... .......... .......... .......... 81%  188M 0s\n",
      "0K .......... .......... .......... .......... .......... 81%  336M 0s\n",
      " .......... .......... .......... 81%  135M 0s\n",
      "......... 81%  279M 0s....... .......... .......... .\n",
      " 41400K .......... .......... .......... .......... .......... 81%  309M 0s\n",
      "41450K .......... .......... .......... .......... .......... 81%  147M 0s\n",
      ".... .......... .......... .......... 82%  247M 0s\n",
      ".. .......... 82%  230M 0s... .......... ........\n",
      "0s1600K .......... .......... .......... .......... .......... 82%  206M \n",
      " 41650K .......... .......... .......... .......... .......... 82%  164M 0s\n",
      "........ .......... .......... .......... 82%  246M 0s\n",
      "...... .......... 82%  228M 0s.......... ....\n",
      "00M 0sK .......... .......... .......... .......... .......... 82%  3\n",
      " 41850K .......... .......... .......... .......... .......... 82%  222M 0s\n",
      ". .......... .......... .......... .......... 82%  309M 0s\n",
      ".......... .......... 82%  163M 0s...... \n",
      "%  348M 0s........ .......... .......... .......... .......... 83\n",
      " 42050K .......... .......... .......... .......... .......... 83%  169M 0s\n",
      "..... .......... .......... .......... .......... 83%  233M 0s\n",
      "... .......... .......... 83%  206M 0s\n",
      ". 83%  331M 0s.... .......... .......... .......... .........\n",
      " 42250K .......... .......... .......... .......... .......... 83%  205M 0s\n",
      "......... .......... .......... .......... .......... 83%  263M 0s\n",
      "....... .......... .......... 83%  221M 0s\n",
      "..... 83%  316M 0s .......... .......... .......... .....\n",
      " 42450K .......... .......... .......... .......... .......... 83%  168M 0s\n",
      "0K .......... .......... .......... .......... .......... 84%  259M 0s\n",
      " .......... .......... .......... 84%  173M 0s\n",
      "......... 84%  292M 0s....... .......... .......... .\n",
      " 42650K .......... .......... .......... .......... .......... 84%  240M 0s\n",
      "42700K .......... .......... .......... .......... .......... 84%  132M 0s\n",
      ".... .......... .......... .......... 84%  272M 0s\n",
      ".. .......... 84%  264M 0s... .......... ........\n",
      "0s2850K .......... .......... .......... .......... .......... 84%  246M \n",
      " 42900K .......... .......... .......... .......... .......... 84%  220M 0s\n",
      "........ .......... .......... .......... 84%  162M 0s\n",
      "...... .......... 85%  301M 0s.......... ....\n",
      "65M 0sK .......... .......... .......... .......... .......... 85%  1\n",
      " 43100K .......... .......... .......... .......... .......... 85%  143M 0s\n",
      ". .......... .......... .......... .......... 85%  214M 0s\n",
      ".......... .......... 85%  274M 0s...... \n",
      "%  225M 0s........ .......... .......... .......... .......... 85\n",
      " 43300K .......... .......... .......... .......... .......... 85%  154M 0s\n",
      "..... .......... .......... .......... .......... 85%  153M 0s\n",
      "... .......... .......... 85%  309M 0s\n",
      ". 85%  270M 0s.... .......... .......... .......... .........\n",
      " 43500K .......... .......... .......... .......... .......... 86%  137M 0s\n",
      "......... .......... .......... .......... .......... 86%  288M 0s\n",
      "....... .......... .......... 86%  254M 0s\n",
      "..... 86%  309M 0s .......... .......... .......... .....\n",
      " 43700K .......... .......... .......... .......... .......... 86%  179M 0s\n",
      "0K .......... .......... .......... .......... .......... 86%  155M 0s\n",
      "....... .......... .......... .......... 86%  238M 0s\n",
      "..... .......... 86%  257M 0s .......... .....\n",
      "8M 0s0K .......... .......... .......... .......... .......... 86%  28\n",
      " 43950K .......... .......... .......... .......... .......... 86%  171M 0s\n",
      " .......... .......... .......... .......... 87%  355M 0s\n",
      "......... .......... 87%  250M 0s....... .\n",
      "  214M 0s......... .......... .......... .......... .......... 87%\n",
      " 44150K .......... .......... .......... .......... .......... 87%  334M 0s\n",
      ".... .......... .......... .......... .......... 87%  177M 0s\n",
      ".. .......... .......... 87%  198M 0s.\n",
      " 87%  274M 0s..... .......... .......... .......... ..........\n",
      " 44350K .......... .......... .......... .......... .......... 87%  355M 0s\n",
      "........ .......... .......... .......... .......... 87%  238M 0s\n",
      "...... .......... .......... 87% 7.55M 0s\n",
      ".... 88%  227M 0s. .......... .......... .......... ......\n",
      " 44550K .......... .......... .......... .......... .......... 88%  299M 0s\n",
      "K .......... .......... .......... .......... .......... 88%  304M 0s\n",
      ".......... .......... .......... 88%  287M 0s\n",
      "........ 88%  242M 0s........ .......... .......... ..\n",
      " 44750K .......... .......... .......... .......... .......... 88%  308M 0s\n",
      "4800K .......... .......... .......... .......... .......... 88%  311M 0s\n",
      "... .......... .......... .......... 88%  306M 0s\n",
      ". .......... 88%  261M 0s.... .......... .........\n",
      "s44950K .......... .......... .......... .......... .......... 88%  303M 0\n",
      " 45000K .......... .......... .......... .......... .......... 88%  335M 0s\n",
      "....... .......... .......... .......... 89%  282M 0s\n",
      "..... .......... 89%  306M 0s .......... .....\n",
      "2M 0s0K .......... .......... .......... .......... .......... 89%  14\n",
      " 45200K .......... .......... .......... .......... .......... 89%  333M 0s\n",
      " .......... .......... .......... .......... 89%  295M 0s\n",
      "......... .......... 89%  269M 0s....... .\n",
      "  139M 0s......... .......... .......... .......... .......... 89%\n",
      " 45400K .......... .......... .......... .......... .......... 89%  292M 0s\n",
      ".... .......... .......... .......... .......... 89%  362M 0s\n",
      ".. .......... .......... 89%  269M 0s.\n",
      " 90%  294M 0s..... .......... .......... .......... ..........\n",
      " 45600K .......... .......... .......... .......... .......... 90%  312M 0s\n",
      "........ .......... .......... .......... .......... 90%  252M 0s\n",
      "...... .......... .......... 90%  135M 0s\n",
      ".... 90%  182M 0s. .......... .......... .......... ......\n",
      " 45800K .......... .......... .......... .......... .......... 90%  401M 0s\n",
      "K .......... .......... .......... .......... .......... 90%  211M 0s\n",
      ".......... .......... .......... 90%  147M 0s\n",
      "........ 90%  168M 0s........ .......... .......... ..\n",
      " 46000K .......... .......... .......... .......... .......... 90%  243M 0s\n",
      "6050K .......... .......... .......... .......... .......... 91%  346M 0s\n",
      "... .......... .......... .......... 91%  277M 0s\n",
      ". .......... 91%  348M 0s.... .......... .........\n",
      "s46200K .......... .......... .......... .......... .......... 91%  164M 0\n",
      " 46250K .......... .......... .......... .......... .......... 91%  171M 0s\n",
      "....... .......... .......... .......... 91%  148M 0s\n",
      "..... .......... 91%  354M 0s .......... .....\n",
      "0M 0s0K .......... .......... .......... .......... .......... 91%  16\n",
      " 46450K .......... .......... .......... .......... .......... 91%  149M 0s\n",
      " .......... .......... .......... .......... 91%  279M 0s\n",
      "......... .......... 92%  337M 0s....... .\n",
      "  173M 0s......... .......... .......... .......... .......... 92%\n",
      " 46650K .......... .......... .......... .......... .......... 92%  154M 0s\n",
      ".... .......... .......... .......... .......... 92%  143M 0s\n",
      ".. .......... .......... 92%  248M 0s.\n",
      " 92%  198M 0s..... .......... .......... .......... ..........\n",
      " 46850K .......... .......... .......... .......... .......... 92%  207M 0s\n",
      "........ .......... .......... .......... .......... 92%  184M 0s\n",
      "...... .......... .......... 92%  330M 0s\n",
      ".... 92%  160M 0s. .......... .......... .......... ......\n",
      " 47050K .......... .......... .......... .......... .......... 93%  193M 0s\n",
      "K .......... .......... .......... .......... .......... 93%  271M 0s\n",
      ".......... .......... .......... 93%  336M 0s\n",
      "........ 93%  348M 0s........ .......... .......... ..\n",
      " 47250K .......... .......... .......... .......... .......... 93%  289M 0s\n",
      "7300K .......... .......... .......... .......... .......... 93%  278M 0s\n",
      "... .......... .......... .......... 93%  321M 0s\n",
      ". .......... 93%  312M 0s.... .......... .........\n",
      "s47450K .......... .......... .......... .......... .......... 93%  301M 0\n",
      " 47500K .......... .......... .......... .......... .......... 93%  299M 0s\n",
      "....... .......... .......... .......... 94%  322M 0s\n",
      "..... .......... 94%  328M 0s .......... .....\n",
      "6M 0s0K .......... .......... .......... .......... .......... 94%  31\n",
      " 47700K .......... .......... .......... .......... .......... 94%  194M 0s\n",
      " .......... .......... .......... .......... 94%  142M 0s\n",
      "......... .......... 94%  138M 0s....... .\n",
      "  141M 0s......... .......... .......... .......... .......... 94%\n",
      " 47900K .......... .......... .......... .......... .......... 94%  121M 0s\n",
      ".... .......... .......... .......... .......... 94%  267M 0s\n",
      ".. .......... .......... 94%  224M 0s.\n",
      " 95%  237M 0s..... .......... .......... .......... ..........\n",
      " 48100K .......... .......... .......... .......... .......... 95%  111M 0s\n",
      "........ .......... .......... .......... .......... 95%  249M 0s\n",
      "...... .......... .......... 95%  104M 0s\n",
      ".... 95%  139M 0s. .......... .......... .......... ......\n",
      " 48300K .......... .......... .......... .......... .......... 95%  139M 0s\n",
      "K .......... .......... .......... .......... .......... 95%  182M 0s\n",
      ".......... .......... .......... 95%  149M 0s\n",
      "........ 95%  168M 0s........ .......... .......... ..\n",
      " 48500K .......... .......... .......... .......... .......... 95%  132M 0s\n",
      "8550K .......... .......... .......... .......... .......... 96%  235M 0s\n",
      "... .......... .......... .......... 96%  306M 0s\n",
      ". .......... 96%  343M 0s.... .......... .........\n",
      "s48700K .......... .......... .......... .......... .......... 96%  267M 0\n",
      " 48750K .......... .......... .......... .......... .......... 96%  319M 0s\n",
      "....... .......... .......... .......... 96%  363M 0s\n",
      "..... .......... 96%  303M 0s .......... .....\n",
      "1M 0s0K .......... .......... .......... .......... .......... 96%  27\n",
      " 48950K .......... .......... .......... .......... .......... 96%  336M 0s\n",
      " .......... .......... .......... .......... 96%  295M 0s\n",
      "......... .......... 96%  298M 0s....... .\n",
      "  307M 0s......... .......... .......... .......... .......... 97%\n",
      " 49150K .......... .......... .......... .......... .......... 97%  317M 0s\n",
      ".... .......... .......... .......... .......... 97%  277M 0s\n",
      ".. .......... .......... 97%  360M 0s.\n",
      " 97%  266M 0s..... .......... .......... .......... ..........\n",
      " 49350K .......... .......... .......... .......... .......... 97%  301M 0s\n",
      "........ .......... .......... .......... .......... 97%  362M 0s\n",
      "...... .......... .......... 97%  313M 0s\n",
      ".... 97%  262M 0s. .......... .......... .......... ......\n",
      " 49550K .......... .......... .......... .......... .......... 97%  325M 0s\n",
      "K .......... .......... .......... .......... .......... 98%  281M 0s\n",
      ".......... .......... .......... 98%  311M 0s\n",
      "........ 98%  301M 0s........ .......... .......... ..\n",
      " 49750K .......... .......... .......... .......... .......... 98%  313M 0s\n",
      "9800K .......... .......... .......... .......... .......... 98%  292M 0s\n",
      "... .......... .......... .......... 98%  351M 0s\n",
      ". .......... 98%  273M 0s.... .......... .........\n",
      "s49950K .......... .......... .......... .......... .......... 98%  314M 0\n",
      " 50000K .......... .......... .......... .......... .......... 98%  309M 0s\n",
      "....... .......... .......... .......... 98%  288M 0s\n",
      "..... .......... 99%  307M 0s .......... .....\n",
      "7M 0s0K .......... .......... .......... .......... .......... 99%  31\n",
      " 50200K .......... .......... .......... .......... .......... 99%  297M 0s\n",
      " .......... .......... .......... .......... 99%  303M 0s\n",
      "......... .......... 99%  277M 0s....... .\n",
      "  306M 0s......... .......... .......... .......... .......... 99%\n",
      " 50400K .......... .......... .......... .......... .......... 99%  320M 0s\n",
      ".... .......... .......... .......... .......... 99%  328M 0s\n",
      ".. .......... .......... 99%  277M 0s.\n",
      " 99%  331M 0s..... .......... .......... .......... ..........\n",
      " 50600K .......... .......... ....                            100%  368M=0.5s\n",
      "\n",
      "-24 09:20:16 (95.4 MB/s) - ‘/tmp/efficientdet.tar.gz’ saved [51839363/51839363]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
      "efficientdet_d1_coco17_tpu-32/checkpoint/checkpoint\n",
      "efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
    "tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint efficientdet_d1_coco17_tpu-32/checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:20:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:20:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=188839;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=573602;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=617863;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=832270;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=969372;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=972799;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:20:19] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tf2-object-detection-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-03-24-09-20-17-842                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:20:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=823508;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=255754;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         tf2-object-detection-\u001b[1;36m2025\u001b[0m-03-24-09-20-17-842                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-24 09:20:19 Starting - Starting the training job...\n",
      "..25-03-24 09:20:42 Starting - Preparing the instances for training.\n",
      "..25-03-24 09:21:14 Downloading - Downloading input data.\n",
      "........24 09:21:29 Downloading - Downloading the training image.\n",
      "\u001b[34m2025-03-24 09:23:24,957 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-24 09:23:24,992 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-24 09:23:25,026 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-24 09:23:25,039 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2025-03-24-09-20-17-842\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-469883407402/tf2-object-detection-2025-03-24-09-20-17-842/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-469883407402/tf2-object-detection-2025-03-24-09-20-17-842/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tf2-object-detection-2025-03-24-09-20-17-842\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-469883407402/tf2-object-detection-2025-03-24-09-20-17-842/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2025-03-24 09:23:25,040 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.680747 139794779739968 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.957642 139794779739968 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.957779 139794779739968 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.966264 139794779739968 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.966355 139794779739968 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.966412 139794779739968 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0324 09:23:30.970148 139794779739968 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.408544 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.411834 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.416711 139794779739968 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.416784 139794779739968 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.434472 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.436800 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.488780 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.491061 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.511482 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.513792 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.562820 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.565113 139794779739968 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.573078 139794779739968 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.573159 139794779739968 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.861246 139794779739968 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:23:33.861370 139794779739968 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:23:34.146889 139794779739968 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:23:34.147014 139794779739968 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:23:34.517602 139794779739968 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:23:34.517723 139794779739968 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:23:34.892108 139794779739968 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:23:34.892238 139794779739968 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.346682 139794779739968 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.346810 139794779739968 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.533414 139794779739968 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.588222 139794779739968 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW0324 09:23:35.762824 139794779739968 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.768929 139794779739968 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.770092 139794779739968 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI0324 09:23:35.770166 139794779739968 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0324 09:23:35.775919 139794779739968 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0324 09:23:35.789231 139794779739968 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:23:41.017358 139794779739968 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:23:44.073659 139794779739968 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0324 09:23:51.524334 139766020437760 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 09:24:00.122473 139766020437760 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW0324 09:24:10.353067 139766237267712 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI0324 09:24:12.398860 139766237267712 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:24:17.649450 139766237267712 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mI0324 09:24:22.307118 139766237267712 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:24:27.463311 139766237267712 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mI0324 09:24:31.324040 139766237267712 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:24:36.507544 139766237267712 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mI0324 09:24:40.588506 139766237267712 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:24:46.274500 139766237267712 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 1.315s\u001b[0m\n",
      "\u001b[34mI0324 09:26:21.409612 139794779739968 model_lib_v2.py:705] Step 100 per-step time 1.315s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.53444386,\n",
      " 'Loss/localization_loss': 0.027999151,\n",
      " 'Loss/regularization_loss': 0.029543556,\n",
      " 'Loss/total_loss': 0.5919866,\n",
      " 'learning_rate': 0.00416}\u001b[0m\n",
      "\u001b[34mI0324 09:26:21.409919 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.53444386,\n",
      " 'Loss/localization_loss': 0.027999151,\n",
      " 'Loss/regularization_loss': 0.029543556,\n",
      " 'Loss/total_loss': 0.5919866,\n",
      " 'learning_rate': 0.00416}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:27:29.595582 139794779739968 model_lib_v2.py:705] Step 200 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.3584325,\n",
      " 'Loss/localization_loss': 0.031528886,\n",
      " 'Loss/regularization_loss': 0.029569022,\n",
      " 'Loss/total_loss': 0.41953042,\n",
      " 'learning_rate': 0.0073200003}\u001b[0m\n",
      "\u001b[34mI0324 09:27:29.595818 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.3584325,\n",
      " 'Loss/localization_loss': 0.031528886,\n",
      " 'Loss/regularization_loss': 0.029569022,\n",
      " 'Loss/total_loss': 0.41953042,\n",
      " 'learning_rate': 0.0073200003}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:28:37.779125 139794779739968 model_lib_v2.py:705] Step 300 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.30767992,\n",
      " 'Loss/localization_loss': 0.021767553,\n",
      " 'Loss/regularization_loss': 0.029571196,\n",
      " 'Loss/total_loss': 0.35901868,\n",
      " 'learning_rate': 0.010480001}\u001b[0m\n",
      "\u001b[34mI0324 09:28:37.779380 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.30767992,\n",
      " 'Loss/localization_loss': 0.021767553,\n",
      " 'Loss/regularization_loss': 0.029571196,\n",
      " 'Loss/total_loss': 0.35901868,\n",
      " 'learning_rate': 0.010480001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:29:45.978621 139794779739968 model_lib_v2.py:705] Step 400 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31159228,\n",
      " 'Loss/localization_loss': 0.015508617,\n",
      " 'Loss/regularization_loss': 0.029572887,\n",
      " 'Loss/total_loss': 0.35667378,\n",
      " 'learning_rate': 0.0136400005}\u001b[0m\n",
      "\u001b[34mI0324 09:29:45.978847 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.31159228,\n",
      " 'Loss/localization_loss': 0.015508617,\n",
      " 'Loss/regularization_loss': 0.029572887,\n",
      " 'Loss/total_loss': 0.35667378,\n",
      " 'learning_rate': 0.0136400005}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:30:54.106575 139794779739968 model_lib_v2.py:705] Step 500 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2454353,\n",
      " 'Loss/localization_loss': 0.0156906,\n",
      " 'Loss/regularization_loss': 0.029580465,\n",
      " 'Loss/total_loss': 0.29070637,\n",
      " 'learning_rate': 0.016800001}\u001b[0m\n",
      "\u001b[34mI0324 09:30:54.106803 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.2454353,\n",
      " 'Loss/localization_loss': 0.0156906,\n",
      " 'Loss/regularization_loss': 0.029580465,\n",
      " 'Loss/total_loss': 0.29070637,\n",
      " 'learning_rate': 0.016800001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:32:02.238279 139794779739968 model_lib_v2.py:705] Step 600 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.269839,\n",
      " 'Loss/localization_loss': 0.014987138,\n",
      " 'Loss/regularization_loss': 0.029591845,\n",
      " 'Loss/total_loss': 0.314418,\n",
      " 'learning_rate': 0.019960001}\u001b[0m\n",
      "\u001b[34mI0324 09:32:02.238519 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.269839,\n",
      " 'Loss/localization_loss': 0.014987138,\n",
      " 'Loss/regularization_loss': 0.029591845,\n",
      " 'Loss/total_loss': 0.314418,\n",
      " 'learning_rate': 0.019960001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:33:10.401671 139794779739968 model_lib_v2.py:705] Step 700 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31052092,\n",
      " 'Loss/localization_loss': 0.024176013,\n",
      " 'Loss/regularization_loss': 0.02960806,\n",
      " 'Loss/total_loss': 0.364305,\n",
      " 'learning_rate': 0.023120001}\u001b[0m\n",
      "\u001b[34mI0324 09:33:10.401920 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.31052092,\n",
      " 'Loss/localization_loss': 0.024176013,\n",
      " 'Loss/regularization_loss': 0.02960806,\n",
      " 'Loss/total_loss': 0.364305,\n",
      " 'learning_rate': 0.023120001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:34:18.489065 139794779739968 model_lib_v2.py:705] Step 800 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2415122,\n",
      " 'Loss/localization_loss': 0.014352514,\n",
      " 'Loss/regularization_loss': 0.029650807,\n",
      " 'Loss/total_loss': 0.28551552,\n",
      " 'learning_rate': 0.02628}\u001b[0m\n",
      "\u001b[34mI0324 09:34:18.489293 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.2415122,\n",
      " 'Loss/localization_loss': 0.014352514,\n",
      " 'Loss/regularization_loss': 0.029650807,\n",
      " 'Loss/total_loss': 0.28551552,\n",
      " 'learning_rate': 0.02628}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:35:26.630767 139794779739968 model_lib_v2.py:705] Step 900 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26604834,\n",
      " 'Loss/localization_loss': 0.017371386,\n",
      " 'Loss/regularization_loss': 0.02968805,\n",
      " 'Loss/total_loss': 0.3131078,\n",
      " 'learning_rate': 0.02944}\u001b[0m\n",
      "\u001b[34mI0324 09:35:26.631000 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.26604834,\n",
      " 'Loss/localization_loss': 0.017371386,\n",
      " 'Loss/regularization_loss': 0.02968805,\n",
      " 'Loss/total_loss': 0.3131078,\n",
      " 'learning_rate': 0.02944}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:36:34.722591 139794779739968 model_lib_v2.py:705] Step 1000 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.22299236,\n",
      " 'Loss/localization_loss': 0.009195255,\n",
      " 'Loss/regularization_loss': 0.029735954,\n",
      " 'Loss/total_loss': 0.26192358,\n",
      " 'learning_rate': 0.0326}\u001b[0m\n",
      "\u001b[34mI0324 09:36:34.722820 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.22299236,\n",
      " 'Loss/localization_loss': 0.009195255,\n",
      " 'Loss/regularization_loss': 0.029735954,\n",
      " 'Loss/total_loss': 0.26192358,\n",
      " 'learning_rate': 0.0326}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 0.700s\u001b[0m\n",
      "\u001b[34mI0324 09:37:44.693814 139794779739968 model_lib_v2.py:705] Step 1100 per-step time 0.700s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26532108,\n",
      " 'Loss/localization_loss': 0.013105389,\n",
      " 'Loss/regularization_loss': 0.029791126,\n",
      " 'Loss/total_loss': 0.30821759,\n",
      " 'learning_rate': 0.03576}\u001b[0m\n",
      "\u001b[34mI0324 09:37:44.694072 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.26532108,\n",
      " 'Loss/localization_loss': 0.013105389,\n",
      " 'Loss/regularization_loss': 0.029791126,\n",
      " 'Loss/total_loss': 0.30821759,\n",
      " 'learning_rate': 0.03576}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:38:52.880599 139794779739968 model_lib_v2.py:705] Step 1200 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.27591428,\n",
      " 'Loss/localization_loss': 0.01292025,\n",
      " 'Loss/regularization_loss': 0.029836757,\n",
      " 'Loss/total_loss': 0.3186713,\n",
      " 'learning_rate': 0.03892}\u001b[0m\n",
      "\u001b[34mI0324 09:38:52.880829 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.27591428,\n",
      " 'Loss/localization_loss': 0.01292025,\n",
      " 'Loss/regularization_loss': 0.029836757,\n",
      " 'Loss/total_loss': 0.3186713,\n",
      " 'learning_rate': 0.03892}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:40:01.101319 139794779739968 model_lib_v2.py:705] Step 1300 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29423237,\n",
      " 'Loss/localization_loss': 0.022692971,\n",
      " 'Loss/regularization_loss': 0.029901287,\n",
      " 'Loss/total_loss': 0.34682664,\n",
      " 'learning_rate': 0.04208}\u001b[0m\n",
      "\u001b[34mI0324 09:40:01.101550 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.29423237,\n",
      " 'Loss/localization_loss': 0.022692971,\n",
      " 'Loss/regularization_loss': 0.029901287,\n",
      " 'Loss/total_loss': 0.34682664,\n",
      " 'learning_rate': 0.04208}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:41:09.271872 139794779739968 model_lib_v2.py:705] Step 1400 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.22783475,\n",
      " 'Loss/localization_loss': 0.01376196,\n",
      " 'Loss/regularization_loss': 0.029978791,\n",
      " 'Loss/total_loss': 0.27157548,\n",
      " 'learning_rate': 0.04524}\u001b[0m\n",
      "\u001b[34mI0324 09:41:09.272100 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.22783475,\n",
      " 'Loss/localization_loss': 0.01376196,\n",
      " 'Loss/regularization_loss': 0.029978791,\n",
      " 'Loss/total_loss': 0.27157548,\n",
      " 'learning_rate': 0.04524}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:42:17.445979 139794779739968 model_lib_v2.py:705] Step 1500 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2716165,\n",
      " 'Loss/localization_loss': 0.01824147,\n",
      " 'Loss/regularization_loss': 0.03004286,\n",
      " 'Loss/total_loss': 0.3199008,\n",
      " 'learning_rate': 0.0484}\u001b[0m\n",
      "\u001b[34mI0324 09:42:17.446211 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.2716165,\n",
      " 'Loss/localization_loss': 0.01824147,\n",
      " 'Loss/regularization_loss': 0.03004286,\n",
      " 'Loss/total_loss': 0.3199008,\n",
      " 'learning_rate': 0.0484}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:43:25.581665 139794779739968 model_lib_v2.py:705] Step 1600 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.27205524,\n",
      " 'Loss/localization_loss': 0.012756735,\n",
      " 'Loss/regularization_loss': 0.030194877,\n",
      " 'Loss/total_loss': 0.31500685,\n",
      " 'learning_rate': 0.05156}\u001b[0m\n",
      "\u001b[34mI0324 09:43:25.581893 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.27205524,\n",
      " 'Loss/localization_loss': 0.012756735,\n",
      " 'Loss/regularization_loss': 0.030194877,\n",
      " 'Loss/total_loss': 0.31500685,\n",
      " 'learning_rate': 0.05156}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:44:33.810832 139794779739968 model_lib_v2.py:705] Step 1700 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25296873,\n",
      " 'Loss/localization_loss': 0.015568662,\n",
      " 'Loss/regularization_loss': 0.030298753,\n",
      " 'Loss/total_loss': 0.29883614,\n",
      " 'learning_rate': 0.05472}\u001b[0m\n",
      "\u001b[34mI0324 09:44:33.811069 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.25296873,\n",
      " 'Loss/localization_loss': 0.015568662,\n",
      " 'Loss/regularization_loss': 0.030298753,\n",
      " 'Loss/total_loss': 0.29883614,\n",
      " 'learning_rate': 0.05472}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:45:41.943068 139794779739968 model_lib_v2.py:705] Step 1800 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2539674,\n",
      " 'Loss/localization_loss': 0.01227968,\n",
      " 'Loss/regularization_loss': 0.030435806,\n",
      " 'Loss/total_loss': 0.2966829,\n",
      " 'learning_rate': 0.05788}\u001b[0m\n",
      "\u001b[34mI0324 09:45:41.943330 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.2539674,\n",
      " 'Loss/localization_loss': 0.01227968,\n",
      " 'Loss/regularization_loss': 0.030435806,\n",
      " 'Loss/total_loss': 0.2966829,\n",
      " 'learning_rate': 0.05788}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 09:46:50.127573 139794779739968 model_lib_v2.py:705] Step 1900 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24606928,\n",
      " 'Loss/localization_loss': 0.014430015,\n",
      " 'Loss/regularization_loss': 0.030513838,\n",
      " 'Loss/total_loss': 0.29101312,\n",
      " 'learning_rate': 0.06104}\u001b[0m\n",
      "\u001b[34mI0324 09:46:50.127816 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.24606928,\n",
      " 'Loss/localization_loss': 0.014430015,\n",
      " 'Loss/regularization_loss': 0.030513838,\n",
      " 'Loss/total_loss': 0.29101312,\n",
      " 'learning_rate': 0.06104}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:47:58.193626 139794779739968 model_lib_v2.py:705] Step 2000 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24312039,\n",
      " 'Loss/localization_loss': 0.011566079,\n",
      " 'Loss/regularization_loss': 0.030624207,\n",
      " 'Loss/total_loss': 0.2853107,\n",
      " 'learning_rate': 0.06420001}\u001b[0m\n",
      "\u001b[34mI0324 09:47:58.193853 139794779739968 model_lib_v2.py:708] {'Loss/classification_loss': 0.24312039,\n",
      " 'Loss/localization_loss': 0.011566079,\n",
      " 'Loss/regularization_loss': 0.030624207,\n",
      " 'Loss/total_loss': 0.2853107,\n",
      " 'learning_rate': 0.06420001}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW0324 09:48:07.347763 139665040602944 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.347936 139665040602944 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.348011 139665040602944 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.348078 139665040602944 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW0324 09:48:07.348165 139665040602944 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.687013 139665040602944 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.687143 139665040602944 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.687214 139665040602944 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.690462 139665040602944 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.721387 139665040602944 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.721518 139665040602944 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.847431 139665040602944 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 09:48:07.847552 139665040602944 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.068477 139665040602944 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.068601 139665040602944 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.281498 139665040602944 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.281621 139665040602944 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.566202 139665040602944 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.566328 139665040602944 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.844390 139665040602944 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:48:08.844516 139665040602944 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.194793 139665040602944 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.194915 139665040602944 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.341961 139665040602944 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.376439 139665040602944 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.550055 139665040602944 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.551060 139665040602944 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI0324 09:48:09.551145 139665040602944 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW0324 09:48:09.551236 139665040602944 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW0324 09:48:09.552768 139665040602944 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0324 09:48:09.554202 139665040602944 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0324 09:48:09.567947 139665040602944 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:48:12.678928 139665040602944 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:48:13.773942 139665040602944 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0324 09:48:15.768271 139665040602944 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI0324 09:48:15.768846 139665040602944 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0324 09:48:22.647158 139665040602944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 09:48:34.154436 139665040602944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:48:39.099273 139665040602944 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0324 09:48:39.136534 139665040602944 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW0324 09:48:39.254637 139665040602944 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0324 09:48:49.675580 139665040602944 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0324 09:48:57.296236 139665040602944 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI0324 09:49:01.490142 139665040602944 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0324 09:49:01.494425 139665040602944 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mI0324 09:49:01.506926 139665040602944 coco_tools.py:138] DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.930685 139665040602944 model_lib_v2.py:1015] Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.089409\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.948958 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.089409\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.216361\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.950337 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.216361\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.058012\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.951289 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.058012\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.038722\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.952164 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.038722\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.306617\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.953112 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.306617\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.407765\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.954046 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.407765\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.020569\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.954910 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.020569\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.097076\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.956132 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.097076\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.137387\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.957011 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.137387\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.079944\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.957876 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.079944\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.439500\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.958741 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.439500\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.640779\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.959663 139665040602944 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.640779\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.020766\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.960362 139665040602944 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.020766\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.298297\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.961069 139665040602944 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.298297\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.030627\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.961755 139665040602944 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.030627\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.349690\u001b[0m\n",
      "\u001b[34mI0324 09:49:09.962429 139665040602944 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.349690\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0324 09:53:15.867792 139665040602944 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI0324 09:53:24.881549 139665040602944 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=8.22s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.009737 139839697770304 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.009882 139839697770304 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.009947 139839697770304 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.013791 139839697770304 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.045006 139839697770304 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.045123 139839697770304 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.171890 139839697770304 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.172012 139839697770304 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.392724 139839697770304 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.392850 139839697770304 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.608018 139839697770304 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.608146 139839697770304 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.890822 139839697770304 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:53:29.890967 139839697770304 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:53:30.183697 139839697770304 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:53:30.183832 139839697770304 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:53:30.529668 139839697770304 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:53:30.529794 139839697770304 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0324 09:53:30.674433 139839697770304 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0324 09:53:30.708300 139839697770304 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW0324 09:53:32.307948 139839697770304 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI0324 09:53:36.451381 139839697770304 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 09:53:45.049407 139839697770304 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 09:53:48.235905 139839697770304 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_classpredictiontower_conv2d_2_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\u001b[0m\n",
      "\u001b[34mI0324 09:53:50.783035 139839697770304 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2e480ee070>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0324 09:53:52.760997 139839697770304 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2e480ee070>, because it is not built.\u001b[0m\n",
      "\u001b[34mI0324 09:54:20.071743 139839697770304 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 535). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0324 09:54:43.332839 139839697770304 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0324 09:54:44.367972 139839697770304 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI0324 09:54:45.585149 139839697770304 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2025-03-24 09:54:47,833 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-03-24 09:55:00 Uploading - Uploading generated training model\n",
      "2025-03-24 09:55:00 Completed - Training job completed\n",
      "Training seconds: 2026\n",
      "Billable seconds: 2026\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\": \"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the initial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the write-up.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your write-up), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17284a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your write-up goes here."
   ]
  },
  {
   "cell_type": "raw",
   "id": "396f6fd0-848d-4234-b45b-79f7907bf1ec",
   "metadata": {},
   "source": [
    "Model Report: CenterNet with ResNet-101 FPN Backbone\n",
    "\n",
    "This model follows the CenterNet meta-architecture based on the paper Objects as Points, using a ResNet-v2-101 backbone with FPN (Feature Pyramid Network). It's designed for anchor-free object detection, where object centers are detected directly as keypoints.\n",
    "\n",
    "Model Architecture\n",
    "Architecture: CenterNet (anchor-free detection)\n",
    "Backbone: ResNet-v2-101\n",
    "Image Input Size: 512 × 512 (resized with aspect ratio + padding)\n",
    "Feature Pyramid Levels: Multi-scale features from ResNet\n",
    "Object Center Loss: Penalty-reduced logistic focal loss (α = 2.0, β = 4.0)\n",
    "Offset and Scale Loss: L1 Localization Loss\n",
    "Max Box Predictions: 100\n",
    "Classes: 90 (COCO dataset format)\n",
    "\n",
    "Training Configuration\n",
    "Batch Size: 128\n",
    "Training Steps: 140,000\n",
    "Learning Rate Strategy: Manual step learning rate\n",
    "Learning Rate Schedule:\n",
    "Step 0: 1e-3\n",
    "Step 90,000: 1e-4\n",
    "Step 120,000: 1e-5\n",
    "Optimizer: Adam (ε = 1e-7)\n",
    "Loss Weights:\n",
    "Classification: 1.0\n",
    "Localization (offset): 1.0\n",
    "Scale loss: 0.1\n",
    "\n",
    "\n",
    "Data Augmentation Used\n",
    "Random Horizontal Flip\n",
    "Random Crop (with min/max aspect ratios)\n",
    "Random Hue, Contrast, Saturation, Brightness\n",
    "Random Absolute Padding (up to 200px black padding)\n",
    "\n",
    "Input & Output Paths\n",
    "Train TFRecords: train2017-?????-of-00256.tfrecord\n",
    "Val TFRecords: val2017-?????-of-00032.tfrecord\n",
    "Label Map: label_map.txt\n",
    "Checkpoint (fine-tuning from classification model): weights-1\n",
    "\n",
    "\n",
    "Training Metrics @ Step 2000\n",
    "Classification Loss: 0.2431\n",
    "Localization Loss: 0.0116\n",
    "Regularization Loss: 0.0306\n",
    "Total Loss: 0.2853\n",
    "Learning Rate: 0.0642\n",
    "\n",
    "COCO Evaluation Metrics (258 Validation Images)\n",
    "mAP@[IoU=0.50:0.95]: 0.089\n",
    "mAP@[IoU=0.50]: 0.216\n",
    "mAP@[IoU=0.75]: 0.058\n",
    "mAP (small objects): 0.039\n",
    "mAP (medium objects): 0.307\n",
    "mAP (large objects): 0.408\n",
    "AR@1: 0.021\n",
    "AR@10: 0.097\n",
    "AR@100: 0.137\n",
    "AR@100 (small): 0.080\n",
    "AR@100 (medium): 0.439\n",
    "AR@100 (large): 0.641\n",
    "\n",
    "\n",
    "Summary & Recommendations\n",
    "Architecture:\n",
    "CenterNet is efficient and accurate for anchor-free detection.\n",
    "Backbone:\n",
    "ResNet-101 offers strong semantic features, especially for large and medium-sized objects.\n",
    "Loss Function:\n",
    "Balanced multi-loss setup; focal loss improves robustness to class imbalance.\n",
    "AP Performance:\n",
    "Performs well on medium and large objects; weaker on small objects — expected behavior for keypoint-based models like CenterNet.\n",
    "Training Health:\n",
    "Loss trends are healthy and stable. Model export was successful.\n",
    "Next Steps:\n",
    "Tune data augmentation strategies\n",
    "Experiment with deeper backbones (e.g., ResNet-152 or HRNet)\n",
    "Improve small object detection using multi-scale features or hybrid anchor + keypoint methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
