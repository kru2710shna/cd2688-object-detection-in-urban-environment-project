{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:52:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:52:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=348122;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=265096;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=350070;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=327099;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::469883407402:role/service-role/AmazonSageMaker-ExecutionRole-20250323T132116\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "          'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://krushnabucket1010/logs/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad5ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# # clone the repo and get the scripts\n",
    "# git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# # get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "# cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "# cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dab3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build and push the docker image. This code can be commented out after being run once.\n",
    "# # This will take around 10 mins.\n",
    "# image_name = 'tf2-object-detection'\n",
    "# !sh ./docker/build_and_push.sh $image_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469883407402.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20250324001031\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be adjusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4b1d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/tmp/checkpoint’: File exists\n",
      "mkdir: cannot create directory ‘source_dir/checkpoint’: File exists\n",
      "--2025-03-24 09:52:25--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.167.207, 142.251.179.207, 64.233.180.207, ...\n",
      "d.tensorflow.org)|142.251.167.207|:80... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 51839363 (49M) [application/x-tar]\n",
      "Saving to: ‘/tmp/efficientdet.tar.gz’\n",
      "\n",
      "........ .......... .......... ..........  0% 9.86M 5s\n",
      "......  0% 20.7M 4s.......... .......... .......... ....\n",
      "...... .......... .......... .......... ..........  0% 20.2M 3s\n",
      "..... .......... .......... ..........  0% 21.1M 3s\n",
      "........ .......... .......... .......... ..........  0% 20.5M 3s\n",
      ".. .......... ..........  0% 13.8M 3s.\n",
      ".... .......... .......... ..........  0% 20.5M 3s\n",
      "...... .......... .......... .......... ..........  0% 20.9M 3s\n",
      "..... .......... .......... .......... ..........  0% 14.3M 3s\n",
      "......... .......... ..........  0% 20.1M 3s\n",
      ".... .......... .......... .......... ..........  1% 21.4M 3s\n",
      "...... .......... ..........  1% 17.3M 3s\n",
      ". .......... .......... ..........  1% 38.9M 3s\n",
      ".... .......... .......... ..........  1% 14.8M 3s\n",
      ".... .......... .......... .......... ..........  1% 30.6M 3s\n",
      ".. .......... .......... .......... ..........  1% 21.3M 3s\n",
      "........ .......... .......... ..........  1% 22.0M 3s\n",
      "......... .......... ..........  1% 43.5M 3s\n",
      " .......... ..........  1% 23.4M 2s.....\n",
      " .......... .......... .......... ..........  1% 23.8M 2s\n",
      "....... .......... ..........  2% 39.4M 2s\n",
      "...... .......... .......... .......... ..........  2% 23.5M 2s\n",
      ". .......... .......... ..........  2% 43.8M 2s\n",
      "......... .......... .......... .......... ..........  2% 23.2M 2s\n",
      " .......... .......... ..........  2% 41.4M 2s\n",
      "......... .......... ..........  2% 20.2M 2s\n",
      "........ .......... ..........  2% 49.6M 2s\n",
      ".... .......... .......... .......... ..........  2% 25.4M 2s\n",
      "..... .......... ..........  2% 39.5M 2s\n",
      ". .......... .......... .......... ..........  2% 24.8M 2s\n",
      "... .......... ..........  3% 43.7M 2s\n",
      "......... .......... .......... ..........  3% 24.3M 2s\n",
      "....... ..........  3% 42.6M 2s......... ...\n",
      "......... .......... .......... .......... ..........  3% 44.0M 2s\n",
      " .......... .......... .......... ..........  3% 25.1M 2s\n",
      "......... ..........  3% 40.1M 2s....... .\n",
      "..... .......... ..........  3% 46.4M 2s\n",
      "...... .......... .......... ..........  3% 44.4M 2s\n",
      "........ .......... .......... .......... ..........  3% 24.1M 2s\n",
      ".. .......... ..........  3% 43.7M 2s.\n",
      "... .......... .......... ..........  4% 44.3M 2s\n",
      ".......  4% 24.4M 2s......... .......... .......... ...\n",
      "........ ..........  4% 44.1M 2s........ ..\n",
      " .......... .......... ..........  4% 45.2M 2s\n",
      ".... .......... .......... .......... ..........  4% 24.1M 2s\n",
      "..... ..........  4% 44.9M 2s .......... .....\n",
      "....... .......... ..........  4% 46.5M 2s\n",
      "......... .......... .......... ..........  4% 44.4M 2s\n",
      ".. .......... .......... ..........  4% 24.0M 2s\n",
      ".... .......... ..........  4% 43.8M 2s\n",
      "..  5% 45.0M 2s... .......... .......... .......... ........\n",
      "....... .......... .......... .......... ..........  5% 24.0M 2s\n",
      ". .......... ..........  5% 45.7M 2s...\n",
      "... .......... .......... ..........  5% 44.3M 2s\n",
      ".... .......... .......... .......... ..........  5% 24.0M 2s\n",
      "........ ..........  5% 44.8M 2s........ ..\n",
      "......... .......... ..........  5% 44.5M 2s\n",
      "..... .......... ..........  5% 26.0M 2s\n",
      "..... ..........  5% 34.5M 2s .......... .....\n",
      "...... .......... ..........  5% 47.3M 2s\n",
      "........ .......... .......... ..........  6% 42.3M 2s\n",
      "....... .......... .......... .......... ..........  6% 25.0M 2s\n",
      "... .......... ..........  6% 45.2M 2s\n",
      "..... .......... .......... ..........  6% 46.6M 2s\n",
      "... ..........  6% 23.7M 2s.. .......... .......\n",
      "  3250K .......... .......... .......... .......... ..........  6% 44.5M 2s\n",
      "3300K .......... .......... .......... .......... ..........  6% 45.2M 2s\n",
      "... .......... .......... .......... ..........  6% 24.2M 2s\n",
      "....... ..........  6% 43.7M 2s......... ...\n",
      "......... .......... ..........  6% 44.1M 2s\n",
      "..  7% 28.1M 2s... .......... .......... .......... ........\n",
      ".... ..........  7% 36.3M 2s. .......... ......\n",
      "..... .......... ..........  7% 43.7M 2s\n",
      "....... .......... .......... ..........  7% 47.2M 2s\n",
      "......... .......... .......... .......... ..........  7% 23.6M 2s\n",
      " .......... ..........  7% 45.1M 2s.....\n",
      ".... .......... .......... ..........  7% 45.1M 2s\n",
      "...... .......... .......... .......... ..........  7% 24.3M 2s\n",
      "......... ..........  7% 43.3M 2s....... .\n",
      ". .......... .......... ..........  7% 47.0M 2s\n",
      "... .......... .......... .......... ..........  8% 23.0M 2s\n",
      "...... ..........  8% 48.5M 2s.......... ....\n",
      "........ .......... ..........  8% 45.1M 2s\n",
      "....  8% 27.0M 2s. .......... .......... .......... ......\n",
      ".........  8% 39.8M 2s....... .......... .......... .\n",
      "..... .......... ..........  8% 36.0M 2s\n",
      " 2s300K .......... .......... .......... .......... ..........  8% 62.6M\n",
      "........ .......... .......... .......... ..........  8% 23.9M 2s\n",
      ".. .......... ..........  8% 45.3M 2s.\n",
      "... .......... .......... ..........  8% 42.7M 2s\n",
      "..... .......... .......... .......... ..........  8% 24.8M 2s\n",
      "........ ..........  9% 43.9M 2s........ ..\n",
      " .......... .......... ..........  9% 42.6M 2s\n",
      ".. .......... .......... .......... ..........  9% 26.7M 2s\n",
      "......... .......... .......... .......... ..........  9% 39.8M 2s\n",
      "....... .......... ..........  9% 44.8M 1s\n",
      "......... .......... .......... ..........  9% 44.3M 1s\n",
      "  4850K .......... .......... .......... .......... ..........  9% 24.3M 1s\n",
      "...... .......... .......... ..........  9% 44.7M 1s\n",
      "...... .......... .......... ..........  9% 43.4M 1s\n",
      "....... .......... .......... .......... ..........  9% 24.5M 1s\n",
      ". .......... .......... 10% 42.2M 1s...\n",
      ". .......... .......... .......... 10% 48.2M 1s\n",
      ".... .......... .......... .......... .......... 10% 24.0M 1s\n",
      "........ .......... 10% 44.8M 1s........ ..\n",
      "40.4M 1s.......... .......... .......... .......... .......... 10% \n",
      ". .......... .......... .......... .......... 10% 23.9M 1s\n",
      "..... .......... 10% 44.2M 1s .......... .....\n",
      ". .......... .......... 10% 46.8M 1s...\n",
      "........ .......... .......... .......... 10% 44.1M 1s\n",
      "... .......... 10% 23.9M 1s.. .......... .......\n",
      "... .......... .......... 11% 45.8M 1s\n",
      "..... .......... .......... .......... 11% 46.6M 1s\n",
      "....... .......... .......... .......... .......... 11% 23.2M 1s\n",
      " .......... .......... 11% 46.6M 1s.....\n",
      ".. .......... .......... .......... 11% 42.4M 1s\n",
      "... .......... .......... .......... .......... 11% 24.7M 1s\n",
      "....... .......... 11% 42.8M 1s......... ...\n",
      "......... .......... .......... 11% 45.2M 1s\n",
      " .......... .......... .......... .......... 11% 24.4M 1s\n",
      "... .......... .......... .......... .......... 11% 43.1M 1s\n",
      "..... .......... .......... 12% 47.0M 1s\n",
      "... .......... .......... .......... 12% 44.1M 1s\n",
      "......... .......... .......... .......... .......... 12% 23.9M 1s\n",
      " .......... .......... 12% 45.7M 1s.....\n",
      ".... .......... .......... .......... 12% 44.5M 1s\n",
      "...... .......... .......... .......... .......... 12% 23.9M 1s\n",
      ".......... .......... 12% 45.2M 1s...... \n",
      ". .......... .......... .......... 12% 46.9M 1s\n",
      ".......... 12% 26.9M 1s...... .......... .......... \n",
      "...... .......... 12% 36.7M 1s.......... ....\n",
      "........ .......... .......... 13% 44.3M 1s\n",
      " .......... .......... .......... .......... 13% 27.5M 1s\n",
      ".. .......... 13% 36.8M 1s... .......... ........\n",
      "..... .......... .......... 13% 44.3M 1s\n",
      "...... .......... .......... .......... 13% 44.6M 1s\n",
      "..... .......... .......... .......... .......... 13% 23.6M 1s\n",
      ".. .......... .......... 13% 48.0M 1s.\n",
      "... .......... .......... .......... 13% 45.6M 1s\n",
      "..... .......... .......... .......... .......... 13% 23.6M 1s\n",
      "........ .......... 13% 46.2M 1s........ ..\n",
      " .......... .......... .......... 14% 44.7M 1s\n",
      "......... .......... .......... .......... 14% 24.2M 1s\n",
      "..... .......... 14% 44.4M 1s .......... .....\n",
      " .......... .......... .......... 14% 46.1M 1s\n",
      "..... 14% 42.1M 1s .......... .......... .......... .....\n",
      ". .......... 14% 24.7M 1s.... .......... .........\n",
      " .......... .......... 14% 44.2M 1s.....\n",
      ".... .......... .......... .......... 14% 46.1M 1s\n",
      "...... .......... .......... .......... .......... 14% 23.5M 1s\n",
      ". .......... .......... 14% 44.3M 1s...\n",
      "... .......... .......... .......... 15% 48.1M 1s\n",
      ".... .......... .......... .......... .......... 15% 22.9M 1s\n",
      "  7650K .......... .......... .......... .......... .......... 15% 47.9M 1s\n",
      "00K .......... .......... .......... .......... .......... 15% 45.7M 1s\n",
      " .......... .......... .......... .......... 15% 26.9M 1s\n",
      "..... .......... 15% 35.6M 1s .......... .....\n",
      "...... .......... .......... 15% 46.6M 1s\n",
      "... .......... .......... .......... .......... 15% 46.4M 1s\n",
      ". .......... 15% 23.6M 1s.... .......... .........\n",
      "... .......... .......... 15% 41.9M 1s\n",
      "...... .......... .......... .......... 16% 49.0M 1s\n",
      "....... .......... .......... .......... .......... 16% 23.6M 1s\n",
      "....... .......... 16% 45.9M 1s......... ...\n",
      ".. .......... .......... .......... 16% 44.5M 1s\n",
      "... .......... .......... .......... .......... 16% 22.5M 1s\n",
      "....... .......... 16% 51.0M 1s......... ...\n",
      "......... .......... .......... 16% 46.3M 1s\n",
      " .......... .......... .......... .......... 16% 27.8M 1s\n",
      ".... .......... 16% 33.9M 1s. .......... ......\n",
      "..... .......... .......... 16% 49.0M 1s\n",
      "....... .......... .......... .......... 16% 35.2M 1s\n",
      "......... .......... .......... .......... .......... 17% 27.6M 1s\n",
      ".. .......... .......... 17% 45.6M 1s.\n",
      ".... .......... .......... .......... 17% 44.1M 1s\n",
      "... .......... .......... .......... .......... 17% 23.7M 1s\n",
      "......... .......... 17% 52.1M 1s....... .\n",
      "...... .......... .......... .......... .......... 17% 42.0M 1s\n",
      "... .......... .......... .......... .......... 17% 25.1M 1s\n",
      "...... .......... 17% 45.4M 1s.......... ....\n",
      "......... .......... .......... .......... 17% 41.4M 1s\n",
      " .......... .......... .......... .......... 17% 26.3M 1s\n",
      "  9100K .......... .......... .......... .......... .......... 18% 41.9M 1s\n",
      "......... .......... .......... .......... .......... 18% 45.1M 1s\n",
      "... 18% 44.5M 1s.. .......... .......... .......... .......\n",
      "........ .......... .......... .......... .......... 18% 24.3M 1s\n",
      ".. .......... .......... 18% 43.2M 1s.\n",
      "......... .......... .......... .......... .......... 18% 46.7M 1s\n",
      "......... .......... .......... .......... .......... 18% 40.3M 1s\n",
      "...... .......... .......... .......... .......... 18% 25.8M 1s\n",
      "  9500K .......... .......... .......... .......... .......... 18% 22.3M 1s\n",
      ".......... .......... .......... .......... .......... 18%  314M 1s\n",
      "........ .......... .......... 19% 60.8M 1s\n",
      "....... .......... .......... 19% 38.6M 1s\n",
      "..... 19% 44.0M 1s .......... .......... .......... .....\n",
      " .......... .......... .......... .......... 19% 32.3M 1s\n",
      "......... .......... .......... .......... .......... 19% 42.1M 1s\n",
      ".... .......... 19% 40.6M 1s. .......... ......\n",
      "M 1s00K .......... .......... .......... .......... .......... 19% 44.9\n",
      "...... .......... .......... 19% 44.9M 1s\n",
      " .......... .......... .......... 19% 47.3M 1s\n",
      "... .......... .......... .......... 19% 47.9M 1s\n",
      "..... .......... .......... .......... 20% 46.0M 1s\n",
      " .......... .......... .......... .......... 20% 38.9M 1s\n",
      ".... .......... .......... .......... .......... 20% 57.0M 1s\n",
      "....... .......... .......... .......... .......... 20% 29.2M 1s\n",
      ".... 20% 37.2M 1s. .......... .......... .......... ......\n",
      "........ 20% 46.2M 1s........ .......... .......... ..\n",
      ". .......... 20% 47.9M 1s.... .......... .........\n",
      "..... .......... 20% 43.4M 1s .......... .....\n",
      "...... .......... .......... .......... .......... 20% 49.5M 1s\n",
      ".. .......... .......... 20% 21.2M 1s.\n",
      " 10600K .......... .......... .......... .......... .......... 21%  333M 1s\n",
      "50K .......... .......... .......... .......... .......... 21% 71.8M 1s\n",
      "...... 21% 44.6M 1s.......... .......... .......... ....\n",
      " 10750K .......... .......... .......... .......... .......... 21% 48.8M 1s\n",
      "00K .......... .......... .......... .......... .......... 21% 46.1M 1s\n",
      "......... .......... 21% 29.1M 1s....... .\n",
      "...... 21% 40.0M 1s.......... .......... .......... ....\n",
      " 10950K .......... .......... .......... .......... .......... 21% 47.4M 1s\n",
      " .......... .......... .......... .......... .......... 21% 47.0M 1s\n",
      "...... .......... 21% 45.1M 1s.......... ....\n",
      "...... .......... 22% 45.4M 1s.......... ....\n",
      "..... .......... 22% 47.9M 1s .......... .....\n",
      "... 22% 46.2M 1s.. .......... .......... .......... .......\n",
      " 11250K .......... .......... .......... .......... .......... 22%  167M 1s\n",
      "......... .......... .......... .......... .......... 22% 63.0M 1s\n",
      " 11350K .......... .......... .......... .......... .......... 22% 49.1M 1s\n",
      ". .......... .......... .......... 22% 11.9M 1s\n",
      " 11450K .......... .......... .......... .......... .......... 22%  309M 1s\n",
      "500K .......... .......... .......... .......... .......... 22%  328M 1s\n",
      ".. .......... .......... .......... 22%  273M 1s\n",
      " .......... 23%  226M 1s..... .......... ..........\n",
      " 11650K .......... .......... .......... .......... .......... 23%  275M 1s\n",
      "...... 23% 13.2M 1s.......... .......... .......... ....\n",
      " 11750K .......... .......... .......... .......... .......... 23%  289M 1s\n",
      "00K .......... .......... .......... .......... .......... 23%  336M 1s\n",
      "...... .......... .......... .......... 23%  358M 1s\n",
      "...... 23%  348M 1s.......... .......... .......... ....\n",
      " 11950K .......... .......... .......... .......... .......... 23%  425M 1s\n",
      "00K .......... .......... .......... .......... .......... 23%  327M 1s\n",
      ". .......... .......... .......... 23%  231M 1s\n",
      ". .......... .......... 24% 79.6M 1s...\n",
      "24% 78.2M 1s...... .......... .......... .......... .......... \n",
      ".... .......... .......... .......... .......... 24% 98.0M 1s\n",
      ".. .......... .......... 24% 9.29M 1s.\n",
      "4%  218M 1s....... .......... .......... .......... .......... 2\n",
      " 12350K .......... .......... .......... .......... .......... 24%  325M 1s\n",
      "...... .......... .......... .......... .......... 24%  273M 1s\n",
      "..... .......... 24%  235M 1s .......... .....\n",
      "3M 1s0K .......... .......... .......... .......... .......... 24%  33\n",
      " 12550K .......... .......... .......... .......... .......... 24%  317M 1s\n",
      " .......... .......... .......... .......... 24%  245M 1s\n",
      "......... .......... 25%  254M 1s....... .\n",
      "  311M 1s......... .......... .......... .......... .......... 25%\n",
      " 12750K .......... .......... .......... .......... .......... 25%  313M 1s\n",
      ".... .......... .......... .......... .......... 25%  300M 1s\n",
      ".... 25%  326M 1s. .......... .......... .......... ......\n",
      " 12900K .......... .......... .......... .......... .......... 25% 93.8M 1s\n",
      "K .......... .......... .......... .......... .......... 25%  166M 1s\n",
      ".......... .......... .......... 25%  298M 1s\n",
      "........ 25%  129M 1s........ .......... .......... ..\n",
      " 13100K .......... .......... .......... .......... .......... 25%  108M 1s\n",
      "3150K .......... .......... .......... .......... .......... 26% 74.9M 1s\n",
      "... .......... .......... .......... 26%  327M 1s\n",
      "...... .......... .......... .......... .......... 26% 6.57M 1s\n",
      ".... .......... .......... 26%  279M 1s\n",
      ".. 26%  201M 1s... .......... .......... .......... ........\n",
      " 13400K .......... .......... .......... .......... .......... 26%  196M 1s\n",
      ".......... .......... .......... .......... .......... 26%  278M 1s\n",
      "........ .......... .......... 26%  307M 1s\n",
      " 13550K .......... .......... .......... .......... .......... 26%  257M 1s\n",
      "3600K .......... .......... .......... .......... .......... 26%  217M 1s\n",
      "... .......... .......... .......... 27%  240M 1s\n",
      ". .......... 27%  185M 1s.... .......... .........\n",
      "s13750K .......... .......... .......... .......... .......... 27%  205M 1\n",
      " 13800K .......... .......... .......... .......... .......... 27%  210M 1s\n",
      "....... .......... .......... .......... 27%  309M 1s\n",
      "..... .......... 27%  198M 1s .......... .....\n",
      "8M 1s0K .......... .......... .......... .......... .......... 27%  16\n",
      " 14000K .......... .......... .......... .......... .......... 27%  237M 1s\n",
      " .......... .......... .......... .......... 27%  226M 1s\n",
      "...... .......... 27%  311M 1s.......... ....\n",
      "45M 1sK .......... .......... .......... .......... .......... 28%  1\n",
      "....... .......... .......... .......... 28%  235M 1s\n",
      "..... .......... 28%  211M 1s .......... .....\n",
      "2M 1s0K .......... .......... .......... .......... .......... 28%  28\n",
      " 14350K .......... .......... .......... .......... .......... 28%  198M 1s\n",
      " .......... .......... .......... .......... 28%  156M 1s\n",
      "......... .......... 28%  257M 1s....... .\n",
      "  221M 1s......... .......... .......... .......... .......... 28%\n",
      " 14550K .......... .......... .......... .......... .......... 28%  191M 1s\n",
      ".... .......... .......... .......... .......... 28%  195M 1s\n",
      ".. .......... .......... 29%  187M 1s.\n",
      " 29%  243M 1s..... .......... .......... .......... ..........\n",
      " 14750K .......... .......... .......... .......... .......... 29%  168M 1s\n",
      "........ .......... .......... .......... .......... 29%  247M 1s\n",
      "...... .......... .......... 29%  222M 1s\n",
      ".... 29%  197M 1s. .......... .......... .......... ......\n",
      " 14950K .......... .......... .......... .......... .......... 29% 86.9M 1s\n",
      "K .......... .......... .......... .......... .......... 29%  142M 1s\n",
      ".......... .......... .......... 29%  225M 1s\n",
      "........ 29%  132M 1s........ .......... .......... ..\n",
      " 15150K .......... .......... .......... .......... .......... 30%  106M 1s\n",
      "5200K .......... .......... .......... .......... .......... 30%  270M 1s\n",
      "........ .......... .......... .......... 30%  286M 1s\n",
      "...... .......... 30%  187M 1s.......... ....\n",
      "35M 1sK .......... .......... .......... .......... .......... 30%  1\n",
      " 15400K .......... .......... .......... .......... .......... 30%  108M 1s\n",
      ". .......... .......... .......... .......... 30%  118M 1s\n",
      ".......... .......... 30%  102M 1s...... \n",
      "%  111M 1s........ .......... .......... .......... .......... 30\n",
      " 15600K .......... .......... .......... .......... .......... 30%  207M 1s\n",
      "..... .......... .......... .......... .......... 31%  172M 1s\n",
      "... .......... .......... 31% 96.8M 1s\n",
      " 15750K .......... .......... .......... .......... .......... 31%  169M 1s\n",
      "...... .......... .......... .......... 31%  189M 1s\n",
      ".... .......... 31%  161M 1s. .......... ......\n",
      "M 1s00K .......... .......... .......... .......... .......... 31%  125\n",
      " 15950K .......... .......... .......... .......... .......... 31%  120M 1s\n",
      ".......... .......... .......... .......... 31%  107M 1s\n",
      "........ .......... 31%  135M 1s........ ..\n",
      " 122M 1s.......... .......... .......... .......... .......... 31% \n",
      " 16150K .......... .......... .......... .......... .......... 32%  183M 1s\n",
      "... .......... .......... .......... .......... 32%  312M 1s\n",
      ". .......... .......... 32% 94.7M 1s...\n",
      "32%  107M 1s...... .......... .......... .......... .......... \n",
      " 16350K .......... .......... .......... .......... .......... 32%  164M 1s\n",
      "....... .......... .......... .......... .......... 32%  200M 1s\n",
      "..... .......... .......... 32%  135M 1s\n",
      "... 32%  169M 1s.. .......... .......... .......... .......\n",
      " 16550K .......... .......... .......... .......... .......... 32%  169M 1s\n",
      " .......... .......... .......... .......... .......... 32%  138M 1s\n",
      "......... .......... .......... 32% 73.6M 1s\n",
      "....... 33%  264M 1s......... .......... .......... ...\n",
      " 16750K .......... .......... .......... .......... .......... 33%  215M 1s\n",
      "800K .......... .......... .......... .......... .......... 33%  101M 1s\n",
      ".. .......... .......... .......... 33%  108M 1s\n",
      " .......... 33%  342M 1s..... .......... ..........\n",
      " 16950K .......... .......... .......... .......... .......... 33%  232M 1s\n",
      " 17000K .......... .......... .......... .......... .......... 33%  279M 1s\n",
      "...... .......... .......... .......... 33%  121M 1s\n",
      ".... .......... 33%  160M 1s. .......... ......\n",
      "M 1s50K .......... .......... .......... .......... .......... 33%  213\n",
      " 17200K .......... .......... .......... .......... .......... 34%  151M 1s\n",
      ".......... .......... .......... .......... 34%  186M 1s\n",
      "........ .......... 34%  306M 1s........ ..\n",
      " 301M 1s.......... .......... .......... .......... .......... 34% \n",
      " 17400K .......... .......... .......... .......... .......... 34%  205M 1s\n",
      "... .......... .......... .......... .......... 34%  237M 1s\n",
      ". .......... .......... 34%  178M 1s...\n",
      "34%  137M 1s...... .......... .......... .......... .......... \n",
      " 17600K .......... .......... .......... .......... .......... 34%  154M 1s\n",
      "....... .......... .......... .......... .......... 34%  207M 1s\n",
      "..... .......... .......... 35%  221M 1s\n",
      "... 35%  132M 1s.. .......... .......... .......... .......\n",
      " 17800K .......... .......... .......... .......... .......... 35%  133M 1s\n",
      " .......... .......... .......... .......... .......... 35%  227M 1s\n",
      "......... .......... .......... 35%  265M 1s\n",
      "....... 35%  194M 1s......... .......... .......... ...\n",
      " 18000K .......... .......... .......... .......... .......... 35%  292M 1s\n",
      "050K .......... .......... .......... .......... .......... 35%  188M 1s\n",
      ".. .......... .......... .......... 35%  180M 1s\n",
      " .......... 35%  187M 1s..... .......... ..........\n",
      " 18200K .......... .......... .......... .......... .......... 36%  271M 1s\n",
      " .......... 36%  183M 1s..... .......... ..........\n",
      ".......... .......... .......... .......... .......... 36%  196M 1s\n",
      "........ .......... .......... 36%  182M 1s\n",
      "...... 36%  239M 1s.......... .......... .......... ....\n",
      " 18450K .......... .......... .......... .......... .......... 36%  271M 1s\n",
      "00K .......... .......... .......... .......... .......... 36%  227M 1s\n",
      ". .......... .......... .......... 36%  198M 1s\n",
      ".......... 36%  257M 1s...... .......... .......... \n",
      " 18650K .......... .......... .......... .......... .......... 36%  166M 1s\n",
      " 18700K .......... .......... .......... .......... .......... 37%  268M 1s\n",
      "..... .......... .......... .......... 37%  200M 1s\n",
      "... .......... 37%  218M 1s.. .......... .......\n",
      " 1s850K .......... .......... .......... .......... .......... 37%  233M\n",
      " 18900K .......... .......... .......... .......... .......... 37%  197M 1s\n",
      "......... .......... .......... .......... 37%  175M 1s\n",
      "....... .......... 37% 42.8M 1s......... ...\n",
      "196M 1s .......... .......... .......... .......... .......... 37%  \n",
      " 19100K .......... .......... .......... .......... .......... 37%  242M 1s\n",
      ".. .......... .......... .......... .......... 37%  214M 1s\n",
      " .......... .......... 38%  149M 1s.....\n",
      "8%  181M 1s....... .......... .......... .......... .......... 3\n",
      " 19300K .......... .......... .......... .......... .......... 38%  210M 1s\n",
      "...... .......... .......... .......... .......... 38%  275M 1s\n",
      ".... .......... .......... 38%  311M 1s\n",
      ".. 38%  315M 1s... .......... .......... .......... ........\n",
      " 19500K .......... .......... .......... .......... .......... 38%  318M 1s\n",
      ".......... .......... .......... .......... .......... 38%  240M 1s\n",
      "........ .......... .......... 38%  175M 1s\n",
      "...... 38% 30.0M 1s.......... .......... .......... ....\n",
      " 19700K .......... .......... .......... .......... .......... 39%  327M 1s\n",
      "50K .......... .......... .......... .......... .......... 39%  278M 1s\n",
      ". .......... .......... .......... 39%  189M 1s\n",
      ".......... 39%  152M 1s...... .......... .......... \n",
      " 19900K .......... .......... .......... .......... .......... 39%  212M 1s\n",
      " 19950K .......... .......... .......... .......... .......... 39%  234M 1s\n",
      "..... .......... .......... .......... 39%  308M 1s\n",
      "... .......... 39%  413M 1s.. .......... .......\n",
      " 1s100K .......... .......... .......... .......... .......... 39%  341M\n",
      " 20150K .......... .......... .......... .......... .......... 39%  276M 1s\n",
      "......... .......... .......... .......... 40%  313M 1s\n",
      "....... .......... 40%  319M 1s......... ...\n",
      "217M 1s .......... .......... .......... .......... .......... 40%  \n",
      " 20350K .......... .......... .......... .......... .......... 40%  230M 1s\n",
      ".. .......... .......... .......... .......... 40% 54.4M 1s\n",
      " .......... .......... 40%  213M 1s.....\n",
      "0%  283M 1s....... .......... .......... .......... .......... 4\n",
      " 20550K .......... .......... .......... .......... .......... 40%  388M 1s\n",
      "...... .......... .......... .......... .......... 40%  326M 1s\n",
      ".... .......... .......... 40%  312M 1s\n",
      ".. 40%  349M 1s... .......... .......... .......... ........\n",
      " 20750K .......... .......... .......... .......... .......... 41%  225M 1s\n",
      ".......... .......... .......... .......... .......... 41%  193M 1s\n",
      "........ .......... .......... 41%  259M 1s\n",
      "...... 41%  219M 1s.......... .......... .......... ....\n",
      " 20950K .......... .......... .......... .......... .......... 41%  267M 1s\n",
      "00K .......... .......... .......... .......... .......... 41%  172M 1s\n",
      ". .......... .......... .......... 41%  146M 1s\n",
      ".......... 41%  197M 1s...... .......... .......... \n",
      " 21150K .......... .......... .......... .......... .......... 41%  305M 1s\n",
      " 21200K .......... .......... .......... .......... .......... 41%  343M 1s\n",
      "..... .......... .......... .......... 42%  276M 1s\n",
      "... .......... 42%  283M 1s.. .......... .......\n",
      " 1s350K .......... .......... .......... .......... .......... 42%  143M\n",
      " 21400K .......... .......... .......... .......... .......... 42%  268M 1s\n",
      "......... .......... .......... .......... 42%  322M 1s\n",
      "....... .......... 42%  328M 1s......... ...\n",
      "305M 1s .......... .......... .......... .......... .......... 42%  \n",
      " 21600K .......... .......... .......... .......... .......... 42%  317M 1s\n",
      ".. .......... .......... .......... .......... 42%  319M 1s\n",
      " .......... .......... 42%  315M 1s.....\n",
      "3%  261M 1s....... .......... .......... .......... .......... 4\n",
      " 21800K .......... .......... .......... .......... .......... 43%  317M 1s\n",
      "...... .......... .......... .......... .......... 43%  329M 1s\n",
      ".... .......... .......... 43%  318M 1s\n",
      ".. 43%  284M 1s... .......... .......... .......... ........\n",
      " 22000K .......... .......... .......... .......... .......... 43%  363M 1s\n",
      ".......... .......... .......... .......... .......... 43%  299M 1s\n",
      "........ .......... .......... 43%  279M 1s\n",
      "...... 43%  303M 1s.......... .......... .......... ....\n",
      " 22200K .......... .......... .......... .......... .......... 43%  318M 1s\n",
      "50K .......... .......... .......... .......... .......... 44%  331M 1s\n",
      ". .......... .......... .......... 44%  362M 1s\n",
      ".......... 44%  276M 1s...... .......... .......... \n",
      " 22400K .......... .......... .......... .......... .......... 44%  323M 1s\n",
      " 22450K .......... .......... .......... .......... .......... 44%  282M 1s\n",
      "..... .......... .......... .......... 44%  406M 1s\n",
      "... .......... 44%  250M 1s.. .......... .......\n",
      " 1s600K .......... .......... .......... .......... .......... 44%  352M\n",
      " 22650K .......... .......... .......... .......... .......... 44%  398M 0s\n",
      "......... .......... .......... .......... 44%  313M 0s\n",
      "....... .......... 45%  267M 0s......... ...\n",
      "388M 0s .......... .......... .......... .......... .......... 45%  \n",
      " 22850K .......... .......... .......... .......... .......... 45%  360M 0s\n",
      ".. .......... .......... .......... .......... 45%  291M 0s\n",
      " .......... .......... 45%  294M 0s.....\n",
      "5%  334M 0s....... .......... .......... .......... .......... 4\n",
      " 23050K .......... .......... .......... .......... .......... 45%  320M 0s\n",
      "...... .......... .......... .......... .......... 45%  322M 0s\n",
      ".... .......... .......... 45%  285M 0s\n",
      ".. 45%  318M 0s... .......... .......... .......... ........\n",
      " 23250K .......... .......... .......... .......... .......... 46%  360M 0s\n",
      ".......... .......... .......... .......... .......... 46%  343M 0s\n",
      "........ .......... .......... 46%  277M 0s\n",
      "...... 46%  324M 0s.......... .......... .......... ....\n",
      " 23450K .......... .......... .......... .......... .......... 46%  364M 0s\n",
      "00K .......... .......... .......... .......... .......... 46%  333M 0s\n",
      ". .......... .......... .......... 46%  278M 0s\n",
      ".......... 46%  322M 0s...... .......... .......... \n",
      " 23650K .......... .......... .......... .......... .......... 46%  384M 0s\n",
      " 23700K .......... .......... .......... .......... .......... 46%  317M 0s\n",
      "..... .......... .......... .......... 47%  240M 0s\n",
      "... .......... 47%  389M 0s.. .......... .......\n",
      " 0s850K .......... .......... .......... .......... .......... 47%  377M\n",
      " 23900K .......... .......... .......... .......... .......... 47%  314M 0s\n",
      "......... .......... .......... .......... 47%  262M 0s\n",
      "....... .......... 47%  402M 0s......... ...\n",
      "363M 0s .......... .......... .......... .......... .......... 47%  \n",
      " 24100K .......... .......... .......... .......... .......... 47%  310M 0s\n",
      ".. .......... .......... .......... .......... 47%  283M 0s\n",
      " .......... .......... 47%  346M 0s.....\n",
      "8%  275M 0s....... .......... .......... .......... .......... 4\n",
      " 24300K .......... .......... .......... .......... .......... 48%  304M 0s\n",
      "...... .......... .......... .......... .......... 48%  316M 0s\n",
      ".... .......... .......... 48%  293M 0s\n",
      ".. 48%  333M 0s... .......... .......... .......... ........\n",
      " 24500K .......... .......... .......... .......... .......... 48%  424M 0s\n",
      ".......... .......... .......... .......... .......... 48% 7.95M 0s\n",
      "........ .......... .......... 48%  140M 0s\n",
      "...... 48% 97.3M 0s.......... .......... .......... ....\n",
      " 24700K .......... .......... .......... .......... .......... 48%  101M 0s\n",
      "50K .......... .......... .......... .......... .......... 48%  235M 0s\n",
      ". .......... .......... .......... 49%  165M 0s\n",
      ".......... 49%  148M 0s...... .......... .......... \n",
      " 24900K .......... .......... .......... .......... .......... 49%  182M 0s\n",
      " 24950K .......... .......... .......... .......... .......... 49%  116M 0s\n",
      "..... .......... .......... .......... 49%  114M 0s\n",
      "... .......... 49%  133M 0s.. .......... .......\n",
      " 0s100K .......... .......... .......... .......... .......... 49%  205M\n",
      " 25150K .......... .......... .......... .......... .......... 49% 95.6M 0s\n",
      "......... .......... .......... .......... 49%  136M 0s\n",
      "....... .......... 49%  116M 0s......... ...\n",
      "134M 0s .......... .......... .......... .......... .......... 50%  \n",
      " 25350K .......... .......... .......... .......... .......... 50%  152M 0s\n",
      ".. .......... .......... .......... .......... 50%  273M 0s\n",
      " .......... .......... 50%  147M 0s.....\n",
      "0% 96.2M 0s....... .......... .......... .......... .......... 5\n",
      " 25550K .......... .......... .......... .......... .......... 50%  184M 0s\n",
      "...... .......... .......... .......... .......... 50%  333M 0s\n",
      ".... .......... .......... 50%  125M 0s\n",
      ".. 50%  321M 0s... .......... .......... .......... ........\n",
      " 25750K .......... .......... .......... .......... .......... 50%  138M 0s\n",
      ".......... .......... .......... .......... .......... 51%  153M 0s\n",
      "........ .......... .......... 51%  112M 0s\n",
      "...... 51%  290M 0s.......... .......... .......... ....\n",
      " 25950K .......... .......... .......... .......... .......... 51%  109M 0s\n",
      "00K .......... .......... .......... .......... .......... 51%  293M 0s\n",
      ". .......... .......... .......... 51% 91.3M 0s\n",
      ".......... 51%  110M 0s...... .......... .......... \n",
      " 26150K .......... .......... .......... .......... .......... 51%  136M 0s\n",
      " 26200K .......... .......... .......... .......... .......... 51%  157M 0s\n",
      "..... .......... .......... .......... 51% 80.6M 0s\n",
      "... .......... 52%  203M 0s.. .......... .......\n",
      " 0s350K .......... .......... .......... .......... .......... 52%  161M\n",
      " 26400K .......... .......... .......... .......... .......... 52%  211M 0s\n",
      "......... .......... .......... .......... 52% 96.7M 0s\n",
      "....... .......... 52% 87.9M 0s......... ...\n",
      "131M 0s .......... .......... .......... .......... .......... 52%  \n",
      " 26600K .......... .......... .......... .......... .......... 52%  144M 0s\n",
      ".. .......... .......... .......... .......... 52%  114M 0s\n",
      " .......... .......... 52%  232M 0s.....\n",
      "2%  126M 0s....... .......... .......... .......... .......... 5\n",
      " 26800K .......... .......... .......... .......... .......... 53%  117M 0s\n",
      "...... .......... .......... .......... .......... 53%  172M 0s\n",
      ".... .......... .......... 53%  168M 0s\n",
      ".. 53%  149M 0s... .......... .......... .......... ........\n",
      " 27000K .......... .......... .......... .......... .......... 53%  164M 0s\n",
      ".......... .......... .......... .......... .......... 53%  184M 0s\n",
      "........ .......... .......... 53%  274M 0s\n",
      "...... 53%  180M 0s.......... .......... .......... ....\n",
      " 27200K .......... .......... .......... .......... .......... 53%  178M 0s\n",
      "50K .......... .......... .......... .......... .......... 53%  181M 0s\n",
      ". .......... .......... .......... 54%  325M 0s\n",
      ".......... 54%  266M 0s...... .......... .......... \n",
      " 27400K .......... .......... .......... .......... .......... 54%  127M 0s\n",
      " 27450K .......... .......... .......... .......... .......... 54%  256M 0s\n",
      "..... .......... .......... .......... 54%  134M 0s\n",
      "... .......... 54%  138M 0s.. .......... .......\n",
      " 0s600K .......... .......... .......... .......... .......... 54%  192M\n",
      " 27650K .......... .......... .......... .......... .......... 54%  127M 0s\n",
      "......... .......... .......... .......... 54%  310M 0s\n",
      "....... .......... 54%  127M 0s......... ...\n",
      "155M 0s .......... .......... .......... .......... .......... 55%  \n",
      " 27850K .......... .......... .......... .......... .......... 55%  134M 0s\n",
      ".. .......... .......... .......... .......... 55%  230M 0s\n",
      " .......... .......... 55%  135M 0s.....\n",
      "5%  259M 0s....... .......... .......... .......... .......... 5\n",
      " 28050K .......... .......... .......... .......... .......... 55%  140M 0s\n",
      "...... .......... .......... .......... .......... 55%  331M 0s\n",
      ".... .......... .......... 55%  185M 0s\n",
      ".. 55%  216M 0s... .......... .......... .......... ........\n",
      " 28250K .......... .......... .......... .......... .......... 55%  115M 0s\n",
      ".......... .......... .......... .......... .......... 56%  165M 0s\n",
      "........ .......... .......... 56%  123M 0s\n",
      "...... 56%  305M 0s.......... .......... .......... ....\n",
      " 28450K .......... .......... .......... .......... .......... 56%  157M 0s\n",
      "00K .......... .......... .......... .......... .......... 56%  239M 0s\n",
      ". .......... .......... .......... 56%  376M 0s\n",
      ".......... 56%  167M 0s...... .......... .......... \n",
      " 28650K .......... .......... .......... .......... .......... 56%  256M 0s\n",
      " 28700K .......... .......... .......... .......... .......... 56%  145M 0s\n",
      "..... .......... .......... .......... 56%  130M 0s\n",
      "... .......... 56%  152M 0s.. .......... .......\n",
      " 0s850K .......... .......... .......... .......... .......... 57%  183M\n",
      " 28900K .......... .......... .......... .......... .......... 57%  128M 0s\n",
      "......... .......... .......... .......... 57%  354M 0s\n",
      "....... .......... 57%  154M 0s......... ...\n",
      "142M 0s .......... .......... .......... .......... .......... 57%  \n",
      " 29100K .......... .......... .......... .......... .......... 57%  108M 0s\n",
      ".. .......... .......... .......... .......... 57%  168M 0s\n",
      " .......... .......... 57%  176M 0s.....\n",
      "7%  130M 0s....... .......... .......... .......... .......... 5\n",
      " 29300K .......... .......... .......... .......... .......... 57%  181M 0s\n",
      "...... .......... .......... .......... .......... 58%  194M 0s\n",
      ".... .......... .......... 58%  187M 0s\n",
      ".. 58%  131M 0s... .......... .......... .......... ........\n",
      " 29500K .......... .......... .......... .......... .......... 58%  149M 0s\n",
      ".......... .......... .......... .......... .......... 58%  162M 0s\n",
      "........ .......... .......... 58%  148M 0s\n",
      "...... 58%  140M 0s.......... .......... .......... ....\n",
      " 29700K .......... .......... .......... .......... .......... 58%  215M 0s\n",
      "50K .......... .......... .......... .......... .......... 58%  124M 0s\n",
      ". .......... .......... .......... 58%  146M 0s\n",
      ".......... 59%  267M 0s...... .......... .......... \n",
      ".... .......... .......... .......... .......... 59%  326M 0s\n",
      ".. .......... .......... 59%  156M 0s.\n",
      ".... .......... .......... 59%  271M 0s\n",
      ".. 59%  149M 0s... .......... .......... .......... ........\n",
      " 30100K .......... .......... .......... .......... .......... 59%  228M 0s\n",
      ".......... .......... .......... .......... .......... 59%  155M 0s\n",
      "........ .......... .......... 59%  119M 0s\n",
      "...... 59%  132M 0s.......... .......... .......... ....\n",
      " 30300K .......... .......... .......... .......... .......... 59%  295M 0s\n",
      "50K .......... .......... .......... .......... .......... 60%  206M 0s\n",
      ". .......... .......... .......... 60%  113M 0s\n",
      ".......... 60%  232M 0s...... .......... .......... \n",
      " 30500K .......... .......... .......... .......... .......... 60%  184M 0s\n",
      " 30550K .......... .......... .......... .......... .......... 60%  268M 0s\n",
      "..... .......... .......... .......... 60%  214M 0s\n",
      "... .......... 60%  142M 0s.. .......... .......\n",
      " 0s700K .......... .......... .......... .......... .......... 60%  202M\n",
      " 30750K .......... .......... .......... .......... .......... 60%  232M 0s\n",
      "......... .......... .......... .......... 60%  247M 0s\n",
      "....... .......... 61%  169M 0s......... ...\n",
      "273M 0s .......... .......... .......... .......... .......... 61%  \n",
      " 30950K .......... .......... .......... .......... .......... 61%  164M 0s\n",
      ".. .......... .......... .......... .......... 61%  156M 0s\n",
      " .......... .......... 61%  152M 0s.....\n",
      "1%  182M 0s....... .......... .......... .......... .......... 6\n",
      " 31150K .......... .......... .......... .......... .......... 61%  209M 0s\n",
      "...... .......... .......... .......... .......... 61%  186M 0s\n",
      ".... .......... .......... 61%  215M 0s\n",
      ".. 61%  175M 0s... .......... .......... .......... ........\n",
      " 31350K .......... .......... .......... .......... .......... 62%  250M 0s\n",
      ".......... .......... .......... .......... .......... 62%  311M 0s\n",
      "........ .......... .......... 62%  269M 0s\n",
      "...... 62%  312M 0s.......... .......... .......... ....\n",
      " 31550K .......... .......... .......... .......... .......... 62%  306M 0s\n",
      "00K .......... .......... .......... .......... .......... 62%  310M 0s\n",
      ". .......... .......... .......... 62%  271M 0s\n",
      ".......... 62%  311M 0s...... .......... .......... \n",
      " 31750K .......... .......... .......... .......... .......... 62%  311M 0s\n",
      " 31800K .......... .......... .......... .......... .......... 62%  309M 0s\n",
      "..... .......... .......... .......... 63%  264M 0s\n",
      "... .......... 63%  311M 0s.. .......... .......\n",
      " 0s950K .......... .......... .......... .......... .......... 63%  315M\n",
      " 32000K .......... .......... .......... .......... .......... 63%  265M 0s\n",
      "......... .......... .......... .......... 63%  238M 0s\n",
      "....... .......... 63%  315M 0s......... ...\n",
      "314M 0s .......... .......... .......... .......... .......... 63%  \n",
      " 32200K .......... .......... .......... .......... .......... 63%  295M 0s\n",
      ".. .......... .......... .......... .......... 63%  269M 0s\n",
      " .......... .......... 63%  308M 0s.....\n",
      "4%  314M 0s....... .......... .......... .......... .......... 6\n",
      " 32400K .......... .......... .......... .......... .......... 64%  287M 0s\n",
      "...... .......... .......... .......... .......... 64%  270M 0s\n",
      ".... .......... .......... 64%  318M 0s\n",
      ".. 64%  273M 0s... .......... .......... .......... ........\n",
      " 32600K .......... .......... .......... .......... .......... 64%  312M 0s\n",
      ".......... .......... .......... .......... .......... 64%  275M 0s\n",
      "........ .......... .......... 64%  268M 0s\n",
      "...... 64%  306M 0s.......... .......... .......... ....\n",
      " 32800K .......... .......... .......... .......... .......... 64%  298M 0s\n",
      "50K .......... .......... .......... .......... .......... 64%  270M 0s\n",
      ". .......... .......... .......... 65%  309M 0s\n",
      ".......... 65%  289M 0s...... .......... .......... \n",
      " 33000K .......... .......... .......... .......... .......... 65%  315M 0s\n",
      " 33050K .......... .......... .......... .......... .......... 65%  270M 0s\n",
      "..... .......... .......... .......... 65%  313M 0s\n",
      "... .......... 65%  293M 0s.. .......... .......\n",
      " 0s200K .......... .......... .......... .......... .......... 65%  281M\n",
      " 33250K .......... .......... .......... .......... .......... 65%  268M 0s\n",
      "......... .......... .......... .......... 65%  292M 0s\n",
      "....... .......... 65%  290M 0s......... ...\n",
      "278M 0s .......... .......... .......... .......... .......... 66%  \n",
      " 33450K .......... .......... .......... .......... .......... 66%  271M 0s\n",
      ".. .......... .......... .......... .......... 66%  306M 0s\n",
      " .......... .......... 66%  288M 0s.....\n",
      "6%  315M 0s....... .......... .......... .......... .......... 6\n",
      " 33650K .......... .......... .......... .......... .......... 66%  263M 0s\n",
      "...... .......... .......... .......... .......... 66%  294M 0s\n",
      ".... .......... .......... 66%  268M 0s\n",
      ".. 66%  279M 0s... .......... .......... .......... ........\n",
      " 33850K .......... .......... .......... .......... .......... 66%  270M 0s\n",
      ".......... .......... .......... .......... .......... 67%  313M 0s\n",
      "........ .......... .......... 67%  288M 0s\n",
      "...... 67%  319M 0s.......... .......... .......... ....\n",
      " 34050K .......... .......... .......... .......... .......... 67%  274M 0s\n",
      "00K .......... .......... .......... .......... .......... 67%  326M 0s\n",
      ". .......... .......... .......... 67%  316M 0s\n",
      ".......... 67%  327M 0s...... .......... .......... \n",
      " 34250K .......... .......... .......... .......... .......... 67%  253M 0s\n",
      " 34300K .......... .......... .......... .......... .......... 67%  309M 0s\n",
      "..... .......... .......... .......... 67%  322M 0s\n",
      "... .......... 68%  283M 0s.. .......... .......\n",
      " 0s450K .......... .......... .......... .......... .......... 68%  255M\n",
      " 34500K .......... .......... .......... .......... .......... 68%  348M 0s\n",
      "......... .......... .......... .......... 68%  373M 0s\n",
      "....... .......... 68%  293M 0s......... ...\n",
      "272M 0s .......... .......... .......... .......... .......... 68%  \n",
      " 34700K .......... .......... .......... .......... .......... 68%  377M 0s\n",
      ".. .......... .......... .......... .......... 68%  318M 0s\n",
      " .......... .......... 68% 3.00M 0s.....\n",
      "8%  138M 0s....... .......... .......... .......... .......... 6\n",
      " 34900K .......... .......... .......... .......... .......... 69%  130M 0s\n",
      "...... .......... .......... .......... .......... 69%  131M 0s\n",
      ".... .......... .......... 69%  207M 0s\n",
      ".. 69%  185M 0s... .......... .......... .......... ........\n",
      " 35100K .......... .......... .......... .......... .......... 69% 86.9M 0s\n",
      ".......... .......... .......... .......... .......... 69%  126M 0s\n",
      "........ .......... .......... 69%  176M 0s\n",
      "...... 69%  109M 0s.......... .......... .......... ....\n",
      " 35300K .......... .......... .......... .......... .......... 69%  214M 0s\n",
      "50K .......... .......... .......... .......... .......... 69%  106M 0s\n",
      ". .......... .......... .......... 70%  125M 0s\n",
      ".......... 70%  175M 0s...... .......... .......... \n",
      " 35500K .......... .......... .......... .......... .......... 70%  141M 0s\n",
      " 35550K .......... .......... .......... .......... .......... 70%  268M 0s\n",
      "..... .......... .......... .......... 70%  151M 0s\n",
      "... .......... 70%  144M 0s.. .......... .......\n",
      " 0s700K .......... .......... .......... .......... .......... 70%  153M\n",
      " 35750K .......... .......... .......... .......... .......... 70%  323M 0s\n",
      "......... .......... .......... .......... 70%  151M 0s\n",
      "....... .......... 70%  284M 0s......... ...\n",
      "160M 0s .......... .......... .......... .......... .......... 71%  \n",
      " 35950K .......... .......... .......... .......... .......... 71%  163M 0s\n",
      ".. .......... .......... .......... .......... 71%  133M 0s\n",
      " .......... .......... 71%  167M 0s.....\n",
      "1%  102M 0s....... .......... .......... .......... .......... 7\n",
      " 36150K .......... .......... .......... .......... .......... 71%  216M 0s\n",
      "...... .......... .......... .......... .......... 71%  222M 0s\n",
      ".... .......... .......... 71%  323M 0s\n",
      ".. 71%  119M 0s... .......... .......... .......... ........\n",
      " 36350K .......... .......... .......... .......... .......... 71%  139M 0s\n",
      ".......... .......... .......... .......... .......... 72%  235M 0s\n",
      "........ .......... .......... 72%  150M 0s\n",
      "...... 72% 93.0M 0s.......... .......... .......... ....\n",
      " 36550K .......... .......... .......... .......... .......... 72%  207M 0s\n",
      "00K .......... .......... .......... .......... .......... 72%  178M 0s\n",
      ". .......... .......... .......... 72%  357M 0s\n",
      ".......... 72%  130M 0s...... .......... .......... \n",
      " 36750K .......... .......... .......... .......... .......... 72%  159M 0s\n",
      " 36800K .......... .......... .......... .......... .......... 72%  300M 0s\n",
      "..... .......... .......... .......... 72%  107M 0s\n",
      "... .......... 72% 65.3M 0s.. .......... .......\n",
      " 0s950K .......... .......... .......... .......... .......... 73%  126M\n",
      " 37000K .......... .......... .......... .......... .......... 73%  322M 0s\n",
      "......... .......... .......... .......... 73% 85.5M 0s\n",
      "....... .......... 73%  152M 0s......... ...\n",
      "120M 0s .......... .......... .......... .......... .......... 73%  \n",
      " 37200K .......... .......... .......... .......... .......... 73%  130M 0s\n",
      ".. .......... .......... .......... .......... 73%  202M 0s\n",
      " .......... .......... 73% 92.8M 0s.....\n",
      "3%  121M 0s....... .......... .......... .......... .......... 7\n",
      " 37400K .......... .......... .......... .......... .......... 73%  186M 0s\n",
      "...... .......... .......... .......... .......... 74%  211M 0s\n",
      ".... .......... .......... 74%  116M 0s\n",
      ".. 74%  293M 0s... .......... .......... .......... ........\n",
      " 37600K .......... .......... .......... .......... .......... 74%  156M 0s\n",
      ".......... .......... .......... .......... .......... 74%  272M 0s\n",
      "........ .......... .......... 74%  135M 0s\n",
      "...... 74%  218M 0s.......... .......... .......... ....\n",
      " 37800K .......... .......... .......... .......... .......... 74%  130M 0s\n",
      "50K .......... .......... .......... .......... .......... 74%  338M 0s\n",
      ". .......... .......... .......... 74%  181M 0s\n",
      ".......... 75%  245M 0s...... .......... .......... \n",
      " 38000K .......... .......... .......... .......... .......... 75%  111M 0s\n",
      " 38050K .......... .......... .......... .......... .......... 75%  191M 0s\n",
      "..... .......... .......... .......... 75%  197M 0s\n",
      "... .......... 75%  138M 0s.. .......... .......\n",
      " 0s200K .......... .......... .......... .......... .......... 75%  143M\n",
      " 38250K .......... .......... .......... .......... .......... 75%  306M 0s\n",
      "......... .......... .......... .......... 75%  205M 0s\n",
      "....... .......... 75%  295M 0s......... ...\n",
      "0.5M 0s .......... .......... .......... .......... .......... 75% 9\n",
      " 38450K .......... .......... .......... .......... .......... 76%  135M 0s\n",
      ".. .......... .......... .......... .......... 76%  146M 0s\n",
      " .......... .......... 76%  227M 0s.....\n",
      "6%  235M 0s....... .......... .......... .......... .......... 7\n",
      " 38650K .......... .......... .......... .......... .......... 76%  139M 0s\n",
      "...... .......... .......... .......... .......... 76%  270M 0s\n",
      ".... .......... .......... 76%  316M 0s\n",
      ".. 76%  176M 0s... .......... .......... .......... ........\n",
      " 38850K .......... .......... .......... .......... .......... 76%  215M 0s\n",
      ".......... .......... .......... .......... .......... 76%  111M 0s\n",
      "........ .......... .......... 77%  192M 0s\n",
      "...... 77%  315M 0s.......... .......... .......... ....\n",
      " 39050K .......... .......... .......... .......... .......... 77%  316M 0s\n",
      "00K .......... .......... .......... .......... .......... 77%  102M 0s\n",
      ". .......... .......... .......... 77%  204M 0s\n",
      ".......... 77%  309M 0s...... .......... .......... \n",
      " 39250K .......... .......... .......... .......... .......... 77%  209M 0s\n",
      " 39300K .......... .......... .......... .......... .......... 77%  197M 0s\n",
      "..... .......... .......... .......... 77%  164M 0s\n",
      "... .......... 77%  183M 0s.. .......... .......\n",
      " 0s450K .......... .......... .......... .......... .......... 78%  227M\n",
      " 39500K .......... .......... .......... .......... .......... 78%  271M 0s\n",
      "......... .......... .......... .......... 78%  174M 0s\n",
      "....... .......... 78%  144M 0s......... ...\n",
      "220M 0s .......... .......... .......... .......... .......... 78%  \n",
      " 39700K .......... .......... .......... .......... .......... 78%  177M 0s\n",
      ".. .......... .......... .......... .......... 78%  137M 0s\n",
      " .......... .......... 78%  247M 0s.....\n",
      "8%  144M 0s....... .......... .......... .......... .......... 7\n",
      " 39900K .......... .......... .......... .......... .......... 78%  126M 0s\n",
      "...... .......... .......... .......... .......... 79%  184M 0s\n",
      ".... .......... .......... 79%  120M 0s\n",
      ".. 79%  197M 0s... .......... .......... .......... ........\n",
      " 40100K .......... .......... .......... .......... .......... 79%  216M 0s\n",
      ".......... .......... .......... .......... .......... 79%  191M 0s\n",
      "........ .......... .......... 79%  232M 0s\n",
      "...... 79%  231M 0s.......... .......... .......... ....\n",
      " 40300K .......... .......... .......... .......... .......... 79%  196M 0s\n",
      "50K .......... .......... .......... .......... .......... 79%  249M 0s\n",
      ". .......... .......... .......... 79%  220M 0s\n",
      ".......... 80%  222M 0s...... .......... .......... \n",
      " 40500K .......... .......... .......... .......... .......... 80%  197M 0s\n",
      " 40550K .......... .......... .......... .......... .......... 80%  319M 0s\n",
      "..... .......... .......... .......... 80%  270M 0s\n",
      "... .......... 80%  217M 0s.. .......... .......\n",
      " 0s700K .......... .......... .......... .......... .......... 80%  180M\n",
      " 40750K .......... .......... .......... .......... .......... 80%  182M 0s\n",
      "......... .......... .......... .......... 80%  260M 0s\n",
      "....... .......... 80%  201M 0s......... ...\n",
      "236M 0s .......... .......... .......... .......... .......... 80%  \n",
      "..... .......... .......... .......... 80%  220M 0s\n",
      "... .......... 81%  307M 0s.. .......... .......\n",
      " 0s050K .......... .......... .......... .......... .......... 81%  196M\n",
      " 41100K .......... .......... .......... .......... .......... 81%  176M 0s\n",
      "......... .......... .......... .......... 81%  208M 0s\n",
      " .......... .......... 81%  306M 0s.....\n",
      "1%  207M 0s....... .......... .......... .......... .......... 8\n",
      " 41300K .......... .......... .......... .......... .......... 81%  226M 0s\n",
      "...... .......... .......... .......... .......... 81%  215M 0s\n",
      ".... .......... .......... 81%  215M 0s\n",
      ".. 81%  275M 0s... .......... .......... .......... ........\n",
      " 41500K .......... .......... .......... .......... .......... 82%  195M 0s\n",
      ".......... .......... .......... .......... .......... 82%  200M 0s\n",
      "........ .......... .......... 82%  213M 0s\n",
      "...... 82%  221M 0s.......... .......... .......... ....\n",
      " 41700K .......... .......... .......... .......... .......... 82%  217M 0s\n",
      "50K .......... .......... .......... .......... .......... 82%  337M 0s\n",
      ". .......... .......... .......... 82%  395M 0s\n",
      ".......... 82%  319M 0s...... .......... .......... \n",
      " 41900K .......... .......... .......... .......... .......... 82%  266M 0s\n",
      " 41950K .......... .......... .......... .......... .......... 82%  349M 0s\n",
      "..... .......... .......... .......... 83%  311M 0s\n",
      "... .......... 83%  340M 0s.. .......... .......\n",
      " 0s100K .......... .......... .......... .......... .......... 83%  270M\n",
      " 42150K .......... .......... .......... .......... .......... 83%  303M 0s\n",
      "......... .......... .......... .......... 83%  309M 0s\n",
      "....... .......... 83%  390M 0s......... ...\n",
      "251M 0s .......... .......... .......... .......... .......... 83%  \n",
      " 42350K .......... .......... .......... .......... .......... 83%  363M 0s\n",
      ".. .......... .......... .......... .......... 83%  436M 0s\n",
      " .......... .......... 83%  350M 0s.....\n",
      "4%  256M 0s....... .......... .......... .......... .......... 8\n",
      " 42550K .......... .......... .......... .......... .......... 84%  324M 0s\n",
      "...... .......... .......... .......... .......... 84%  322M 0s\n",
      ".... .......... .......... 84%  280M 0s\n",
      ".. 84%  308M 0s... .......... .......... .......... ........\n",
      " 42750K .......... .......... .......... .......... .......... 84%  312M 0s\n",
      ".......... .......... .......... .......... .......... 84%  256M 0s\n",
      "........ .......... .......... 84%  344M 0s\n",
      "...... 84%  281M 0s.......... .......... .......... ....\n",
      " 42950K .......... .......... .......... .......... .......... 84%  321M 0s\n",
      "00K .......... .......... .......... .......... .......... 85%  312M 0s\n",
      ". .......... .......... .......... 85%  325M 0s\n",
      ".......... 85%  269M 0s...... .......... .......... \n",
      " 43150K .......... .......... .......... .......... .......... 85%  328M 0s\n",
      " 43200K .......... .......... .......... .......... .......... 85%  347M 0s\n",
      "..... .......... .......... .......... 85%  293M 0s\n",
      "... .......... 85%  301M 0s.. .......... .......\n",
      " 0s350K .......... .......... .......... .......... .......... 85%  299M\n",
      " 43400K .......... .......... .......... .......... .......... 85%  292M 0s\n",
      "......... .......... .......... .......... 85%  358M 0s\n",
      "....... .......... 86%  272M 0s......... ...\n",
      "315M 0s .......... .......... .......... .......... .......... 86%  \n",
      " 43600K .......... .......... .......... .......... .......... 86%  329M 0s\n",
      ".. .......... .......... .......... .......... 86%  307M 0s\n",
      " .......... .......... 86%  277M 0s.....\n",
      "6%  362M 0s....... .......... .......... .......... .......... 8\n",
      " 43800K .......... .......... .......... .......... .......... 86%  315M 0s\n",
      "...... .......... .......... .......... .......... 86%  314M 0s\n",
      ".... .......... .......... 86%  268M 0s\n",
      ".. 86%  311M 0s... .......... .......... .......... ........\n",
      " 44000K .......... .......... .......... .......... .......... 87%  311M 0s\n",
      ".......... .......... .......... .......... .......... 87%  328M 0s\n",
      "........ .......... .......... 87%  263M 0s\n",
      "...... 87%  318M 0s.......... .......... .......... ....\n",
      " 44200K .......... .......... .......... .......... .......... 87%  250M 0s\n",
      "50K .......... .......... .......... .......... .......... 87%  163M 0s\n",
      ". .......... .......... .......... 87%  147M 0s\n",
      ".......... 87%  201M 0s...... .......... .......... \n",
      " 44400K .......... .......... .......... .......... .......... 87%  261M 0s\n",
      " 44450K .......... .......... .......... .......... .......... 87%  211M 0s\n",
      "..... .......... .......... .......... 88%  123M 0s\n",
      "... .......... 88%  159M 0s.. .......... .......\n",
      " 0s600K .......... .......... .......... .......... .......... 88%  185M\n",
      " 44650K .......... .......... .......... .......... .......... 88%  178M 0s\n",
      "......... .......... .......... .......... 88%  150M 0s\n",
      "....... .......... 88%  132M 0s......... ...\n",
      "151M 0s .......... .......... .......... .......... .......... 88%  \n",
      " 44850K .......... .......... .......... .......... .......... 88%  152M 0s\n",
      ".. .......... .......... .......... .......... 88%  105M 0s\n",
      " .......... .......... 88%  141M 0s.....\n",
      "8%  299M 0s....... .......... .......... .......... .......... 8\n",
      " 45050K .......... .......... .......... .......... .......... 89%  398M 0s\n",
      "...... .......... .......... .......... .......... 89%  226M 0s\n",
      ".... .......... .......... 89%  176M 0s\n",
      ".. 89%  307M 0s... .......... .......... .......... ........\n",
      " 45250K .......... .......... .......... .......... .......... 89%  305M 0s\n",
      ".......... .......... .......... .......... .......... 89%  289M 0s\n",
      "........ .......... .......... 89%  351M 0s\n",
      "...... 89%  320M 0s.......... .......... .......... ....\n",
      " 45450K .......... .......... .......... .......... .......... 89%  325M 0s\n",
      "00K .......... .......... .......... .......... .......... 89%  292M 0s\n",
      ". .......... .......... .......... 90%  312M 0s\n",
      ".......... 90%  353M 0s...... .......... .......... \n",
      " 45650K .......... .......... .......... .......... .......... 90%  329M 0s\n",
      " 45700K .......... .......... .......... .......... .......... 90%  273M 0s\n",
      "..... .......... .......... .......... 90%  328M 0s\n",
      "... .......... 90%  292M 0s.. .......... .......\n",
      " 0s850K .......... .......... .......... .......... .......... 90%  322M\n",
      " 45900K .......... .......... .......... .......... .......... 90%  283M 0s\n",
      "......... .......... .......... .......... 90%  365M 0s\n",
      "....... .......... 90%  290M 0s......... ...\n",
      "296M 0s .......... .......... .......... .......... .......... 91%  \n",
      " 46100K .......... .......... .......... .......... .......... 91%  281M 0s\n",
      ".. .......... .......... .......... .......... 91%  319M 0s\n",
      " .......... .......... 91%  329M 0s.....\n",
      "1%  325M 0s....... .......... .......... .......... .......... 9\n",
      " 46300K .......... .......... .......... .......... .......... 91%  274M 0s\n",
      "...... .......... .......... .......... .......... 91%  304M 0s\n",
      ".... .......... .......... 91%  412M 0s\n",
      ".. 91%  322M 0s... .......... .......... .......... ........\n",
      " 46500K .......... .......... .......... .......... .......... 91%  274M 0s\n",
      ".......... .......... .......... .......... .......... 92%  362M 0s\n",
      "........ .......... .......... 92%  292M 0s\n",
      "...... 92%  313M 0s.......... .......... .......... ....\n",
      " 46700K .......... .......... .......... .......... .......... 92%  309M 0s\n",
      "50K .......... .......... .......... .......... .......... 92%  274M 0s\n",
      ". .......... .......... .......... 92%  318M 0s\n",
      ".......... 92%  342M 0s...... .......... .......... \n",
      " 46900K .......... .......... .......... .......... .......... 92%  272M 0s\n",
      " 46950K .......... .......... .......... .......... .......... 92%  322M 0s\n",
      "..... .......... .......... .......... 92%  354M 0s\n",
      "... .......... 93%  264M 0s.. .......... .......\n",
      " 0s100K .......... .......... .......... .......... .......... 93% 10.2M\n",
      " 47150K .......... .......... .......... .......... .......... 93%  100M 0s\n",
      "......... .......... .......... .......... 93%  225M 0s\n",
      "....... .......... 93%  153M 0s......... ...\n",
      "176M 0s .......... .......... .......... .......... .......... 93%  \n",
      " 47350K .......... .......... .......... .......... .......... 93%  101M 0s\n",
      ".. .......... .......... .......... .......... 93%  120M 0s\n",
      " .......... .......... 93%  145M 0s.....\n",
      "3%  107M 0s....... .......... .......... .......... .......... 9\n",
      " 47550K .......... .......... .......... .......... .......... 94% 92.3M 0s\n",
      "...... .......... .......... .......... .......... 94%  120M 0s\n",
      ".... .......... .......... 94% 91.6M 0s\n",
      ".. 94%  232M 0s... .......... .......... .......... ........\n",
      " 47750K .......... .......... .......... .......... .......... 94%  250M 0s\n",
      ".......... .......... .......... .......... .......... 94%  219M 0s\n",
      "........ .......... .......... 94%  181M 0s\n",
      "...... 94%  158M 0s.......... .......... .......... ....\n",
      " 47950K .......... .......... .......... .......... .......... 94%  331M 0s\n",
      "00K .......... .......... .......... .......... .......... 94%  222M 0s\n",
      ". .......... .......... .......... 95%  275M 0s\n",
      ".......... 95%  232M 0s...... .......... .......... \n",
      " 48150K .......... .......... .......... .......... .......... 95%  320M 0s\n",
      " 48200K .......... .......... .......... .......... .......... 95%  312M 0s\n",
      "..... .......... .......... .......... 95%  219M 0s\n",
      "... .......... 95%  314M 0s.. .......... .......\n",
      " 0s350K .......... .......... .......... .......... .......... 95%  282M\n",
      " 48400K .......... .......... .......... .......... .......... 95%  360M 0s\n",
      "......... .......... .......... .......... 95%  190M 0s\n",
      "....... .......... 95%  242M 0s......... ...\n",
      "320M 0s .......... .......... .......... .......... .......... 96%  \n",
      " 48600K .......... .......... .......... .......... .......... 96%  230M 0s\n",
      ".. .......... .......... .......... .......... 96%  277M 0s\n",
      " .......... .......... 96%  309M 0s.....\n",
      "6%  225M 0s....... .......... .......... .......... .......... 9\n",
      " 48800K .......... .......... .......... .......... .......... 96%  303M 0s\n",
      "...... .......... .......... .......... .......... 96%  264M 0s\n",
      ".... .......... .......... 96%  385M 0s\n",
      ".. 96%  377M 0s... .......... .......... .......... ........\n",
      " 49000K .......... .......... .......... .......... .......... 96%  426M 0s\n",
      ".......... .......... .......... .......... .......... 96%  380M 0s\n",
      "........ .......... .......... 97%  410M 0s\n",
      "...... 97% 1.75M 0s.......... .......... .......... ....\n",
      " 49200K .......... .......... .......... .......... .......... 97%  265M 0s\n",
      "50K .......... .......... .......... .......... .......... 97%  247M 0s\n",
      ". .......... .......... .......... 97%  293M 0s\n",
      ".......... 97%  260M 0s...... .......... .......... \n",
      " 49400K .......... .......... .......... .......... .......... 97%  283M 0s\n",
      " 49450K .......... .......... .......... .......... .......... 97%  255M 0s\n",
      "..... .......... .......... .......... 97%  308M 0s\n",
      "... .......... 97%  274M 0s.. .......... .......\n",
      " 0s600K .......... .......... .......... .......... .......... 98%  261M\n",
      " 49650K .......... .......... .......... .......... .......... 98%  222M 0s\n",
      "......... .......... .......... .......... 98%  263M 0s\n",
      "....... .......... 98%  315M 0s......... ...\n",
      "329M 0s .......... .......... .......... .......... .......... 98%  \n",
      " 49850K .......... .......... .......... .......... .......... 98%  277M 0s\n",
      ".. .......... .......... .......... .......... 98%  244M 0s\n",
      " .......... .......... 98%  287M 0s.....\n",
      "8%  315M 0s....... .......... .......... .......... .......... 9\n",
      " 50050K .......... .......... .......... .......... .......... 98%  311M 0s\n",
      "...... .......... .......... .......... .......... 99%  266M 0s\n",
      ".... .......... .......... 99%  266M 0s\n",
      ".. 99%  306M 0s... .......... .......... .......... ........\n",
      " 50250K .......... .......... .......... .......... .......... 99%  251M 0s\n",
      ".......... .......... .......... .......... .......... 99%  297M 0s\n",
      "........ .......... .......... 99%  302M 0s\n",
      "...... 99%  289M 0s.......... .......... .......... ....\n",
      " 50450K .......... .......... .......... .......... .......... 99%  280M 0s\n",
      "00K .......... .......... .......... .......... .......... 99%  322M 0s\n",
      ". .......... .......... .......... 99%  291M 0s\n",
      "          100%  306M=0.6s.... ....                  \n",
      "\n",
      "1839363/51839363]26 (83.5 MB/s) - ‘/tmp/efficientdet.tar.gz’ saved [5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
      "efficientdet_d1_coco17_tpu-32/checkpoint/checkpoint\n",
      "efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
    "tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint efficientdet_d1_coco17_tpu-32/checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:52:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:52:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=241997;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=557394;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=540984;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=678567;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=306525;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=684195;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:52:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tf2-object-detection-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-03-24-09-52-27-533                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/24/25 09:52:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=285543;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=910755;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         tf2-object-detection-\u001b[1;36m2025\u001b[0m-03-24-09-52-27-533                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-24 09:52:30 Starting - Starting the training job...\n",
      "..25-03-24 09:52:44 Starting - Preparing the instances for training.\n",
      "...........09:53:31 Downloading - Downloading the training image.\n",
      "2025-03-24 09:55:07 Training - Training image download completed. Training in progress.\u001b[34m2025-03-24 09:55:21,648 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-24 09:55:21,682 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-24 09:55:21,716 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-24 09:55:21,730 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2025-03-24-09-52-27-533\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-469883407402/tf2-object-detection-2025-03-24-09-52-27-533/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-469883407402/tf2-object-detection-2025-03-24-09-52-27-533/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tf2-object-detection-2025-03-24-09-52-27-533\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-469883407402/tf2-object-detection-2025-03-24-09-52-27-533/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2025-03-24 09:55:21,730 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.403099 139668594718528 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.675987 139668594718528 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.676129 139668594718528 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.684278 139668594718528 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.684367 139668594718528 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.684432 139668594718528 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0324 09:55:27.688019 139668594718528 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.462648 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.465491 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.470172 139668594718528 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.470249 139668594718528 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.487845 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.490104 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.541988 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.544355 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.564790 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.567299 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.616251 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.618649 139668594718528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.626480 139668594718528 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.626557 139668594718528 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.910814 139668594718528 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 09:55:29.910941 139668594718528 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:55:30.188614 139668594718528 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 09:55:30.188736 139668594718528 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:55:30.554256 139668594718528 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 09:55:30.554385 139668594718528 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:55:30.920548 139668594718528 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 09:55:30.920676 139668594718528 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.373412 139668594718528 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.373536 139668594718528 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.558882 139668594718528 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.612703 139668594718528 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW0324 09:55:31.788571 139668594718528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.794566 139668594718528 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.795724 139668594718528 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI0324 09:55:31.795804 139668594718528 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0324 09:55:31.801519 139668594718528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0324 09:55:31.815105 139668594718528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:55:37.221064 139668594718528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0324 09:55:40.315003 139668594718528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0324 09:55:47.882730 139640031975168 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 09:55:56.446670 139640031975168 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW0324 09:56:06.602088 139640042465024 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI0324 09:56:08.589200 139640042465024 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:56:14.072243 139640042465024 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mI0324 09:56:18.429844 139640042465024 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:56:23.863765 139640042465024 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mI0324 09:56:27.351935 139640042465024 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:56:32.467275 139640042465024 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mI0324 09:56:36.917159 139640042465024 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mW0324 09:56:42.004163 139640042465024 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 1.309s\u001b[0m\n",
      "\u001b[34mI0324 09:58:17.206861 139668594718528 model_lib_v2.py:705] Step 100 per-step time 1.309s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.45778748,\n",
      " 'Loss/localization_loss': 0.037280407,\n",
      " 'Loss/regularization_loss': 0.029542731,\n",
      " 'Loss/total_loss': 0.52461064,\n",
      " 'learning_rate': 0.00416}\u001b[0m\n",
      "\u001b[34mI0324 09:58:17.207155 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.45778748,\n",
      " 'Loss/localization_loss': 0.037280407,\n",
      " 'Loss/regularization_loss': 0.029542731,\n",
      " 'Loss/total_loss': 0.52461064,\n",
      " 'learning_rate': 0.00416}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 09:59:25.284464 139668594718528 model_lib_v2.py:705] Step 200 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.48757774,\n",
      " 'Loss/localization_loss': 0.08091951,\n",
      " 'Loss/regularization_loss': 0.029546106,\n",
      " 'Loss/total_loss': 0.5980433,\n",
      " 'learning_rate': 0.0073200003}\u001b[0m\n",
      "\u001b[34mI0324 09:59:25.284693 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.48757774,\n",
      " 'Loss/localization_loss': 0.08091951,\n",
      " 'Loss/regularization_loss': 0.029546106,\n",
      " 'Loss/total_loss': 0.5980433,\n",
      " 'learning_rate': 0.0073200003}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 0.680s\u001b[0m\n",
      "\u001b[34mI0324 10:00:33.308260 139668594718528 model_lib_v2.py:705] Step 300 per-step time 0.680s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31022182,\n",
      " 'Loss/localization_loss': 0.018650964,\n",
      " 'Loss/regularization_loss': 0.029547587,\n",
      " 'Loss/total_loss': 0.35842037,\n",
      " 'learning_rate': 0.010480001}\u001b[0m\n",
      "\u001b[34mI0324 10:00:33.308487 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.31022182,\n",
      " 'Loss/localization_loss': 0.018650964,\n",
      " 'Loss/regularization_loss': 0.029547587,\n",
      " 'Loss/total_loss': 0.35842037,\n",
      " 'learning_rate': 0.010480001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 10:01:41.380721 139668594718528 model_lib_v2.py:705] Step 400 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29923508,\n",
      " 'Loss/localization_loss': 0.017714929,\n",
      " 'Loss/regularization_loss': 0.029556986,\n",
      " 'Loss/total_loss': 0.34650698,\n",
      " 'learning_rate': 0.0136400005}\u001b[0m\n",
      "\u001b[34mI0324 10:01:41.380956 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.29923508,\n",
      " 'Loss/localization_loss': 0.017714929,\n",
      " 'Loss/regularization_loss': 0.029556986,\n",
      " 'Loss/total_loss': 0.34650698,\n",
      " 'learning_rate': 0.0136400005}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 10:02:49.481010 139668594718528 model_lib_v2.py:705] Step 500 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2467631,\n",
      " 'Loss/localization_loss': 0.01568108,\n",
      " 'Loss/regularization_loss': 0.029567,\n",
      " 'Loss/total_loss': 0.29201117,\n",
      " 'learning_rate': 0.016800001}\u001b[0m\n",
      "\u001b[34mI0324 10:02:49.481239 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.2467631,\n",
      " 'Loss/localization_loss': 0.01568108,\n",
      " 'Loss/regularization_loss': 0.029567,\n",
      " 'Loss/total_loss': 0.29201117,\n",
      " 'learning_rate': 0.016800001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:03:57.680831 139668594718528 model_lib_v2.py:705] Step 600 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29933771,\n",
      " 'Loss/localization_loss': 0.016874203,\n",
      " 'Loss/regularization_loss': 0.029590284,\n",
      " 'Loss/total_loss': 0.3458022,\n",
      " 'learning_rate': 0.019960001}\u001b[0m\n",
      "\u001b[34mI0324 10:03:57.681068 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.29933771,\n",
      " 'Loss/localization_loss': 0.016874203,\n",
      " 'Loss/regularization_loss': 0.029590284,\n",
      " 'Loss/total_loss': 0.3458022,\n",
      " 'learning_rate': 0.019960001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mI0324 10:05:05.947852 139668594718528 model_lib_v2.py:705] Step 700 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.30914935,\n",
      " 'Loss/localization_loss': 0.014444645,\n",
      " 'Loss/regularization_loss': 0.029609835,\n",
      " 'Loss/total_loss': 0.35320383,\n",
      " 'learning_rate': 0.023120001}\u001b[0m\n",
      "\u001b[34mI0324 10:05:05.948076 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.30914935,\n",
      " 'Loss/localization_loss': 0.014444645,\n",
      " 'Loss/regularization_loss': 0.029609835,\n",
      " 'Loss/total_loss': 0.35320383,\n",
      " 'learning_rate': 0.023120001}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:06:14.117640 139668594718528 model_lib_v2.py:705] Step 800 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25735083,\n",
      " 'Loss/localization_loss': 0.0140067795,\n",
      " 'Loss/regularization_loss': 0.029634144,\n",
      " 'Loss/total_loss': 0.30099177,\n",
      " 'learning_rate': 0.02628}\u001b[0m\n",
      "\u001b[34mI0324 10:06:14.117873 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.25735083,\n",
      " 'Loss/localization_loss': 0.0140067795,\n",
      " 'Loss/regularization_loss': 0.029634144,\n",
      " 'Loss/total_loss': 0.30099177,\n",
      " 'learning_rate': 0.02628}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:07:22.366183 139668594718528 model_lib_v2.py:705] Step 900 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25931948,\n",
      " 'Loss/localization_loss': 0.01162732,\n",
      " 'Loss/regularization_loss': 0.029670022,\n",
      " 'Loss/total_loss': 0.30061683,\n",
      " 'learning_rate': 0.02944}\u001b[0m\n",
      "\u001b[34mI0324 10:07:22.366413 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.25931948,\n",
      " 'Loss/localization_loss': 0.01162732,\n",
      " 'Loss/regularization_loss': 0.029670022,\n",
      " 'Loss/total_loss': 0.30061683,\n",
      " 'learning_rate': 0.02944}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mI0324 10:08:30.629207 139668594718528 model_lib_v2.py:705] Step 1000 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24508767,\n",
      " 'Loss/localization_loss': 0.014797555,\n",
      " 'Loss/regularization_loss': 0.02973022,\n",
      " 'Loss/total_loss': 0.28961545,\n",
      " 'learning_rate': 0.0326}\u001b[0m\n",
      "\u001b[34mI0324 10:08:30.629439 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.24508767,\n",
      " 'Loss/localization_loss': 0.014797555,\n",
      " 'Loss/regularization_loss': 0.02973022,\n",
      " 'Loss/total_loss': 0.28961545,\n",
      " 'learning_rate': 0.0326}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 0.700s\u001b[0m\n",
      "\u001b[34mI0324 10:09:40.588895 139668594718528 model_lib_v2.py:705] Step 1100 per-step time 0.700s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2710066,\n",
      " 'Loss/localization_loss': 0.016453965,\n",
      " 'Loss/regularization_loss': 0.02977468,\n",
      " 'Loss/total_loss': 0.31723523,\n",
      " 'learning_rate': 0.03576}\u001b[0m\n",
      "\u001b[34mI0324 10:09:40.589129 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.2710066,\n",
      " 'Loss/localization_loss': 0.016453965,\n",
      " 'Loss/regularization_loss': 0.02977468,\n",
      " 'Loss/total_loss': 0.31723523,\n",
      " 'learning_rate': 0.03576}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:10:48.835874 139668594718528 model_lib_v2.py:705] Step 1200 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25523674,\n",
      " 'Loss/localization_loss': 0.017227054,\n",
      " 'Loss/regularization_loss': 0.029837137,\n",
      " 'Loss/total_loss': 0.30230093,\n",
      " 'learning_rate': 0.03892}\u001b[0m\n",
      "\u001b[34mI0324 10:10:48.836097 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.25523674,\n",
      " 'Loss/localization_loss': 0.017227054,\n",
      " 'Loss/regularization_loss': 0.029837137,\n",
      " 'Loss/total_loss': 0.30230093,\n",
      " 'learning_rate': 0.03892}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:11:57.022069 139668594718528 model_lib_v2.py:705] Step 1300 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2181027,\n",
      " 'Loss/localization_loss': 0.012445155,\n",
      " 'Loss/regularization_loss': 0.029905804,\n",
      " 'Loss/total_loss': 0.26045364,\n",
      " 'learning_rate': 0.04208}\u001b[0m\n",
      "\u001b[34mI0324 10:11:57.022295 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.2181027,\n",
      " 'Loss/localization_loss': 0.012445155,\n",
      " 'Loss/regularization_loss': 0.029905804,\n",
      " 'Loss/total_loss': 0.26045364,\n",
      " 'learning_rate': 0.04208}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mI0324 10:13:05.343978 139668594718528 model_lib_v2.py:705] Step 1400 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.23623076,\n",
      " 'Loss/localization_loss': 0.011479239,\n",
      " 'Loss/regularization_loss': 0.029978275,\n",
      " 'Loss/total_loss': 0.27768826,\n",
      " 'learning_rate': 0.04524}\u001b[0m\n",
      "\u001b[34mI0324 10:13:05.344210 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.23623076,\n",
      " 'Loss/localization_loss': 0.011479239,\n",
      " 'Loss/regularization_loss': 0.029978275,\n",
      " 'Loss/total_loss': 0.27768826,\n",
      " 'learning_rate': 0.04524}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:14:13.568628 139668594718528 model_lib_v2.py:705] Step 1500 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31432998,\n",
      " 'Loss/localization_loss': 0.013799051,\n",
      " 'Loss/regularization_loss': 0.030051073,\n",
      " 'Loss/total_loss': 0.3581801,\n",
      " 'learning_rate': 0.0484}\u001b[0m\n",
      "\u001b[34mI0324 10:14:13.568851 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.31432998,\n",
      " 'Loss/localization_loss': 0.013799051,\n",
      " 'Loss/regularization_loss': 0.030051073,\n",
      " 'Loss/total_loss': 0.3581801,\n",
      " 'learning_rate': 0.0484}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 10:15:21.717712 139668594718528 model_lib_v2.py:705] Step 1600 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.22446905,\n",
      " 'Loss/localization_loss': 0.0169479,\n",
      " 'Loss/regularization_loss': 0.030124467,\n",
      " 'Loss/total_loss': 0.27154142,\n",
      " 'learning_rate': 0.05156}\u001b[0m\n",
      "\u001b[34mI0324 10:15:21.717943 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.22446905,\n",
      " 'Loss/localization_loss': 0.0169479,\n",
      " 'Loss/regularization_loss': 0.030124467,\n",
      " 'Loss/total_loss': 0.27154142,\n",
      " 'learning_rate': 0.05156}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 10:16:29.799522 139668594718528 model_lib_v2.py:705] Step 1700 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24145317,\n",
      " 'Loss/localization_loss': 0.00902117,\n",
      " 'Loss/regularization_loss': 0.03022292,\n",
      " 'Loss/total_loss': 0.28069726,\n",
      " 'learning_rate': 0.05472}\u001b[0m\n",
      "\u001b[34mI0324 10:16:29.799765 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.24145317,\n",
      " 'Loss/localization_loss': 0.00902117,\n",
      " 'Loss/regularization_loss': 0.03022292,\n",
      " 'Loss/total_loss': 0.28069726,\n",
      " 'learning_rate': 0.05472}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mI0324 10:17:38.095921 139668594718528 model_lib_v2.py:705] Step 1800 per-step time 0.683s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29377252,\n",
      " 'Loss/localization_loss': 0.024222594,\n",
      " 'Loss/regularization_loss': 0.030381003,\n",
      " 'Loss/total_loss': 0.3483761,\n",
      " 'learning_rate': 0.05788}\u001b[0m\n",
      "\u001b[34mI0324 10:17:38.096147 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.29377252,\n",
      " 'Loss/localization_loss': 0.024222594,\n",
      " 'Loss/regularization_loss': 0.030381003,\n",
      " 'Loss/total_loss': 0.3483761,\n",
      " 'learning_rate': 0.05788}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mI0324 10:18:46.257615 139668594718528 model_lib_v2.py:705] Step 1900 per-step time 0.682s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31336835,\n",
      " 'Loss/localization_loss': 0.024926698,\n",
      " 'Loss/regularization_loss': 0.030498598,\n",
      " 'Loss/total_loss': 0.36879364,\n",
      " 'learning_rate': 0.06104}\u001b[0m\n",
      "\u001b[34mI0324 10:18:46.257843 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.31336835,\n",
      " 'Loss/localization_loss': 0.024926698,\n",
      " 'Loss/regularization_loss': 0.030498598,\n",
      " 'Loss/total_loss': 0.36879364,\n",
      " 'learning_rate': 0.06104}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mI0324 10:19:54.357752 139668594718528 model_lib_v2.py:705] Step 2000 per-step time 0.681s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21812394,\n",
      " 'Loss/localization_loss': 0.0076295757,\n",
      " 'Loss/regularization_loss': 0.030593377,\n",
      " 'Loss/total_loss': 0.25634688,\n",
      " 'learning_rate': 0.06420001}\u001b[0m\n",
      "\u001b[34mI0324 10:19:54.357981 139668594718528 model_lib_v2.py:708] {'Loss/classification_loss': 0.21812394,\n",
      " 'Loss/localization_loss': 0.0076295757,\n",
      " 'Loss/regularization_loss': 0.030593377,\n",
      " 'Loss/total_loss': 0.25634688,\n",
      " 'learning_rate': 0.06420001}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW0324 10:20:03.314467 139754126890816 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.314629 139754126890816 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.314707 139754126890816 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.314785 139754126890816 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW0324 10:20:03.314884 139754126890816 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.651336 139754126890816 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.651463 139754126890816 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.651507 139754126890816 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.654751 139754126890816 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.685464 139754126890816 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.685582 139754126890816 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.808435 139754126890816 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 10:20:03.808557 139754126890816 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.024237 139754126890816 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.024363 139754126890816 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.236034 139754126890816 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.236167 139754126890816 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.517706 139754126890816 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.517834 139754126890816 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.794210 139754126890816 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 10:20:04.794339 139754126890816 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.132784 139754126890816 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.132912 139754126890816 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.278131 139754126890816 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.313910 139754126890816 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.487367 139754126890816 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.488367 139754126890816 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI0324 10:20:05.488454 139754126890816 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW0324 10:20:05.488525 139754126890816 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW0324 10:20:05.490071 139754126890816 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0324 10:20:05.491483 139754126890816 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0324 10:20:05.505235 139754126890816 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0324 10:20:08.531464 139754126890816 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0324 10:20:09.619040 139754126890816 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0324 10:20:11.626248 139754126890816 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI0324 10:20:11.626810 139754126890816 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0324 10:20:18.435402 139754126890816 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 10:20:29.937947 139754126890816 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0324 10:20:34.833292 139754126890816 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0324 10:20:34.870944 139754126890816 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW0324 10:20:34.987489 139754126890816 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0324 10:20:45.092009 139754126890816 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0324 10:20:52.364772 139754126890816 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI0324 10:20:56.604974 139754126890816 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0324 10:20:56.608594 139754126890816 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mI0324 10:20:56.620477 139754126890816 coco_tools.py:138] DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.959820 139754126890816 model_lib_v2.py:1015] Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.104205\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.978208 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.104205\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.245072\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.979595 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.245072\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.078042\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.980555 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.078042\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.043529\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.981472 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.043529\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.379594\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.982320 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.379594\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.324477\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.983231 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.324477\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.024173\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.984179 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.024173\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.110322\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.984998 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.110322\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.152845\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.985858 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.152845\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.091557\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.986729 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.091557\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.463253\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.987580 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.463253\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.542015\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.988526 139754126890816 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.542015\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.018772\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.989214 139754126890816 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.018772\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.329535\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.989922 139754126890816 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.329535\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.030594\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.990616 139754126890816 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.030594\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.378901\u001b[0m\n",
      "\u001b[34mI0324 10:21:04.991287 139754126890816 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.378901\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0324 10:25:11.723938 139754126890816 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI0324 10:25:20.737474 139754126890816 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=8.13s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34mI0324 10:25:24.853101 140180208113472 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0324 10:25:24.853242 140180208113472 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0324 10:25:24.853307 140180208113472 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0324 10:25:24.857095 140180208113472 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 10:25:24.887825 140180208113472 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0324 10:25:24.887943 140180208113472 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.011155 140180208113472 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.011282 140180208113472 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.229061 140180208113472 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.229189 140180208113472 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.441806 140180208113472 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.441936 140180208113472 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.719766 140180208113472 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0324 10:25:25.719885 140180208113472 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 10:25:26.011360 140180208113472 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0324 10:25:26.011485 140180208113472 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 10:25:26.351560 140180208113472 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0324 10:25:26.351708 140180208113472 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0324 10:25:26.505280 140180208113472 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0324 10:25:26.539757 140180208113472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW0324 10:25:28.133512 140180208113472 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI0324 10:25:32.233182 140180208113472 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 10:25:40.759225 140180208113472 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0324 10:25:43.956879 140180208113472 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_classpredictiontower_conv2d_2_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\u001b[0m\n",
      "\u001b[34mI0324 10:25:46.470415 140180208113472 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f7d9009e6a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0324 10:25:48.447887 140180208113472 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f7d9009e6a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mI0324 10:26:15.463659 140180208113472 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 535). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0324 10:26:39.105730 140180208113472 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0324 10:26:40.146283 140180208113472 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI0324 10:26:41.378946 140180208113472 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2025-03-24 10:26:43,629 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-03-24 10:26:57 Uploading - Uploading generated training model\n",
      "2025-03-24 10:26:57 Completed - Training job completed\n",
      "Training seconds: 2022\n",
      "Billable seconds: 2022\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\": \"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the initial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the write-up.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your write-up), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17284a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your write-up goes here."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa696dad-e8d9-40f8-8be4-f242c704aaae",
   "metadata": {},
   "source": [
    "Model Architecture\n",
    "Architecture: Mask R-CNN (region-based detection with segmentation)\n",
    "Backbone: Inception ResNet v2 (Keras implementation, no atrous convolution)\n",
    "Image Input Size: 1024 × 1024 (fixed shape resizer)\n",
    "Anchor Generator: Multi-scale (0.25, 0.5, 1.0, 2.0) and aspect ratios (0.5, 1.0, 2.0)\n",
    "Region Proposal Network (RPN):\n",
    "NMS threshold: 0.7\n",
    "Max Proposals: 300\n",
    "ROI Align Crop Size: 17\n",
    "Mask Prediction Head:\n",
    "Output Size: 33×33\n",
    "Layers: 4 conv layers\n",
    "Instance Segmentation Support: Enabled\n",
    "Classes: 90 (COCO dataset format)\n",
    "\n",
    "\n",
    "Training Configuration\n",
    "Batch Size: 16\n",
    "Training Steps: 200,000\n",
    "Optimizer: Momentum Optimizer (momentum = 0.9)\n",
    "Learning Rate Strategy: Cosine decay\n",
    "Initial LR: 0.008\n",
    "Warm-up LR: 0.0\n",
    "Warm-up steps: 5000\n",
    "Gradient Clipping: 10.0 norm\n",
    "Checkpoint Init: ImageNet classification weights\n",
    "Loss Weights:\n",
    "Classification: 1.0\n",
    "Localization: 2.0\n",
    "Mask Loss: 4.0\n",
    "\n",
    "\n",
    "Training Metrics @ Step 2000\n",
    "Classification Loss: 0.2181\n",
    "Localization Loss: 0.0076\n",
    "Regularization Loss: 0.0306\n",
    "Total Loss: 0.2563\n",
    "Learning Rate: 0.0642\n",
    "\n",
    "COCO Evaluation Metrics (258 Validation Images)\n",
    "mAP@[IoU=0.50:0.95]: 0.104\n",
    "mAP@[IoU=0.50]: 0.245\n",
    "mAP@[IoU=0.75]: 0.078\n",
    "mAP (small objects): 0.044\n",
    "mAP (medium objects): 0.380\n",
    "mAP (large objects): 0.324\n",
    "AR@1: 0.024\n",
    "AR@10: 0.110\n",
    "AR@100: 0.153\n",
    "AR@100 (small): 0.092\n",
    "AR@100 (medium): 0.463\n",
    "AR@100 (large): 0.542\n",
    "\n",
    "Summary & Recommendations\n",
    "Strengths:\n",
    "Good performance on medium and large objects\n",
    "Strong segmentation support (via instance masks)\n",
    "Stable and fast convergence, low total loss (~0.25–0.37 early on)\n",
    "Weaknesses:\n",
    "Lower small object detection (mAP ~0.04)\n",
    "Suggestions:\n",
    "Enhance small object detection using finer anchors or image tiling\n",
    "Increase training steps (if loss keeps dropping)\n",
    "Add multi-scale training and more diverse augmentations\n",
    "Fine-tune mask prediction layers separately for better mask mAP\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3b4c4-be5d-45cf-94ce-00c34b772648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
